{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "BERT-CNN",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "omfN5AZ9ys_g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46a23a73-2313-4982-925b-55b1af60e832"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QhEGRaVVaFh"
      },
      "source": [
        "## Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrvPcIuR1Qnt"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "formspring = \"/content/gdrive/My Drive/formspring_data_BERT_210323.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYhj-RIeybIm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38f737ce-7050-423b-fd68-f5a0d2332b9c"
      },
      "source": [
        "import pickle as pc\n",
        "import os\n",
        "import numpy as np\n",
        "import csv\n",
        "import torch\n",
        "\n",
        "# torch 버전 확인\n",
        "print(\"Pytorch Version: \", torch.__version__)\n",
        "\n",
        "# GPU 사용 가능한지 여부 확인\n",
        "if torch.cuda.is_available():\n",
        "    \n",
        "    # PyTorch 에게 GPU 사용할거라고 알려주기\n",
        "    device = torch.device(\"cuda\")\n",
        "    \n",
        "    print(\"There are %d GPU(s) available.\" % torch.cuda.device_count())\n",
        "    print(\"We will use the GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"No GPU available, using the CPU instead.\")\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pytorch Version:  1.8.1+cu101\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DoBvLNQV3wj"
      },
      "source": [
        "## Installing the Hugging Face Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrMn70gSV3Ko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7588a953-45b1-4d4b-a96f-1121f95eb6c6"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1In5hQtPybIs"
      },
      "source": [
        "def load_data(filename):\n",
        "    data = list()\n",
        "    label = list()\n",
        "    \n",
        "    f = open(filename, 'r', encoding='latin1')\n",
        "    reader = csv.reader(f)\n",
        "    for idx, line in enumerate(reader):\n",
        "        if idx == 0:\n",
        "            continue\n",
        "\n",
        "        data.append(line[0])\n",
        "        label.append(int(line[2]))\n",
        "\n",
        "    f.close()\n",
        "    \n",
        "    # data 랑 label 사이즈 일치 여부 확인\n",
        "    assert len(data) == len(label)\n",
        "    return data, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USBIeV1TybIv"
      },
      "source": [
        "formspring_data, formspring_label = load_data(formspring)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xdoo53fTwn4"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(formspring_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VnJHbkAWFzI"
      },
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "df4 = df[0].apply(lambda x: x.replace('Q:',' ').replace('A:',' ').replace('<br>',' '))\n",
        "df4 = df4.apply(lambda x: x.lower())\n",
        "df4 = df4.apply((lambda x: re.sub(r\"(https?|http)://[-a-zA-Z0-9+&@#/%?=~_|!:,.;]*[-a-zA-Z0-9+&@#/%=~_|]\", \"\", x)))\n",
        "df4 = df4.apply((lambda x: re.sub(r\"&#039;\", \"\\'\", x)))\n",
        "df4 = df4.apply((lambda x: re.sub(r\"&quot;\", \"\", x)))\n",
        "df4 = df4.apply((lambda x: re.sub(r\"&amp;\", \"\", x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaYyh100VGNe"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "data = list(np.array(df4.tolist()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp9DkK9bVdQH"
      },
      "source": [
        "formspring_data = data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjZNhURn4il1",
        "outputId": "bb58e8d9-417a-4bcb-b2bf-ef6066198e5d"
      },
      "source": [
        "print(\"Size of imdb data: {}\".format(len(formspring_data)))\n",
        "print(\"Size of imdb label: {}\".format(len(formspring_label)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of imdb data: 12773\n",
            "Size of imdb label: 12773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL-P6sSM4uFX"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, test_data, train_label, test_label = train_test_split(formspring_data, formspring_label, test_size = 0.2, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43O3FuU7ybI0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ee7f99f-aad1-4c8d-c449-2f6aa0bbc288"
      },
      "source": [
        "print(\"Size of train data: {}\".format(len(train_data)))\n",
        "print(\"Size of train label: {}\".format(len(train_label)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of train data: 10218\n",
            "Size of train label: 10218\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Uq8AHTb48_r"
      },
      "source": [
        "import numpy as np\n",
        "test_data = np.array(test_data)\n",
        "test_label = np.array(test_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kks51eZ9ybJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69baa9a0-171a-4150-86d0-78179beb8a85"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# BERT tokenizer 불러오기\n",
        "print(\"Loading BERT tokenizer...\")\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTwSHYz1ybJG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "122c57b5-a78b-4c46-da5d-7ac49d65d087"
      },
      "source": [
        "# 하나의 sentence 에 대해 BertTokenizer 적용\n",
        "\n",
        "# Print the original sentence.\n",
        "print(\"Original: \", train_data[0])\n",
        "print()\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print(\"Tokenized: \", tokenizer.tokenize(train_data[0]))\n",
        "print()\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print(\"Token IDs: \", tokenizer.convert_tokens_to_ids(tokenizer.tokenize(train_data[0])))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:    haha thanks to you or i would have never been named an honerary ninja :)   haha yeeee im awesome(:\n",
            "\n",
            "Tokenized:  ['ha', '##ha', 'thanks', 'to', 'you', 'or', 'i', 'would', 'have', 'never', 'been', 'named', 'an', 'hon', '##era', '##ry', 'ninja', ':', ')', 'ha', '##ha', 'ye', '##ee', '##e', 'im', 'awesome', '(', ':']\n",
            "\n",
            "Token IDs:  [5292, 3270, 4283, 2000, 2017, 2030, 1045, 2052, 2031, 2196, 2042, 2315, 2019, 10189, 6906, 2854, 14104, 1024, 1007, 5292, 3270, 6300, 4402, 2063, 10047, 12476, 1006, 1024]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDJ4ZBtizGK5"
      },
      "source": [
        "#### Sentences to IDs\n",
        "\n",
        "`tokenizer.encode` 함수를 이용하여 모든 문장들에 대해 위의 과정들을 한꺼번에 처리합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qArPy88KybJM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7de036a0-c96f-4c45-ccba-61ab934c9974"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence\n",
        "for sent in train_data:\n",
        "    # 'encode' will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the '[CLS]' token to the start.\n",
        "    #   (3) Append the '[SEP]' token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    \n",
        "    encoded_sent = tokenizer.encode(sent, \n",
        "                                    add_special_tokens=True,\n",
        "                                    max_length = 62)\n",
        "    \n",
        "    # Add the encoded sentence to the list\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print train data[0]\n",
        "print(\"Original: \", train_data[0])\n",
        "print()\n",
        "print(\"Token IDs: \", input_ids[0])\n",
        "\n",
        "# Print special tokens and tokenized sentence\n",
        "print(\"\\n[CLS] token: {:}, ID: {:}\".format(tokenizer.cls_token, tokenizer.cls_token_id))\n",
        "print(\"\\n[PAD] token: {:}, ID: {:}\".format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "print(\"\\n[SEP] token: {:}, ID: {:}\".format(tokenizer.sep_token, tokenizer.sep_token_id))\n",
        "print(\"\\nTokenized: \", tokenizer.convert_ids_to_tokens(input_ids[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:    haha thanks to you or i would have never been named an honerary ninja :)   haha yeeee im awesome(:\n",
            "\n",
            "Token IDs:  [101, 5292, 3270, 4283, 2000, 2017, 2030, 1045, 2052, 2031, 2196, 2042, 2315, 2019, 10189, 6906, 2854, 14104, 1024, 1007, 5292, 3270, 6300, 4402, 2063, 10047, 12476, 1006, 1024, 102]\n",
            "\n",
            "[CLS] token: [CLS], ID: 101\n",
            "\n",
            "[PAD] token: [PAD], ID: 0\n",
            "\n",
            "[SEP] token: [SEP], ID: 102\n",
            "\n",
            "Tokenized:  ['[CLS]', 'ha', '##ha', 'thanks', 'to', 'you', 'or', 'i', 'would', 'have', 'never', 'been', 'named', 'an', 'hon', '##era', '##ry', 'ninja', ':', ')', 'ha', '##ha', 'ye', '##ee', '##e', 'im', 'awesome', '(', ':', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKm4AQMFybJP"
      },
      "source": [
        "#### Padding & Truncating\n",
        "\n",
        "`tf.keras.preprocessing.sequence.pad_sequences` 를 이용하여 **MAXLEN** 만큼 padding 과정을 진행합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvi1_q33ybJQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc064434-2fd1-4142-a084-25e0dffba4e6"
      },
      "source": [
        "print(\"Max length: \", max([len(each) for each in input_ids]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max length:  62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTelEtVNybJV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cd71612-8419-4e1e-a46f-02568fadb881"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"Tensorflow version: {}\".format(tf.__version__))\n",
        "\n",
        "MAXLEN = 62\n",
        "\n",
        "input_ids = tf.keras.preprocessing.sequence.pad_sequences(input_ids, \n",
        "                                                          maxlen=MAXLEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print(\"\\nDone.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.5.0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJnT5boqybJY"
      },
      "source": [
        "#### Attention Masks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maKvU-KKybJZ"
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence\n",
        "for sent in input_ids:\n",
        "    # Create the attention mask.\n",
        "    #  - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #  - If a token ID is not 0 ( > 0), then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISSN2XpEybJc"
      },
      "source": [
        "#### Training & Validation Split\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTLBXYLTybJg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adad878d-2d84-4f7f-9e87-c5346255680b"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, valid_inputs, train_labels, valid_labels = train_test_split(input_ids, train_label, random_state=2018, test_size=0.1)\n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks, valid_masks, _, _ = train_test_split(attention_masks, train_label, random_state=2018, test_size=0.1)\n",
        "\n",
        "# print train_inputs, valid_inputs\n",
        "print(train_inputs[:1])\n",
        "print(train_masks[:1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  101 10047 11471  2024  2017 11471  1029  1024  1011  1013  2748 10047\n",
            "  11471  1012  1012  1012  8840  2140   102     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0]]\n",
            "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_jmnF2IybJj"
      },
      "source": [
        "#### Converting to PyTorch Data Types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hFzBxvyybJk"
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required data type for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "valid_inputs = torch.tensor(valid_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "valid_labels = torch.tensor(valid_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "valid_masks = torch.tensor(valid_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhbYgxdvybJq"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it here.\n",
        "# For fine-tuning BERT on a specific task, we recommend a batch size of 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_labels, valid_labels = (torch.FloatTensor(t) for t in (train_labels.float(), valid_labels.float()))\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "valid_data = TensorDataset(valid_inputs, valid_masks, valid_labels)\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dZaKTuLDh3f"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class BertCNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, embed_size, bert_model):\n",
        "        super(BertCNN, self).__init__()\n",
        "        filter_sizes = [2,3]\n",
        "        num_filters = 32\n",
        "        self.convs1 = nn.ModuleList([nn.Conv2d(4, num_filters, (K, embed_size)) for K in filter_sizes])\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc1 = nn.Linear(len(filter_sizes)*num_filters, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.bert_model = bert_model\n",
        "\n",
        "    def forward(self, x, input_masks, token_type_ids):\n",
        "        x = self.bert_model(x, attention_mask=input_masks, token_type_ids=token_type_ids)[2][-4:]\n",
        "        x = torch.stack(x, dim=1)\n",
        "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1] \n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  \n",
        "        x = torch.cat(x, 1)\n",
        "        x = self.dropout(x)  \n",
        "        logit = self.fc1(x)\n",
        "        return self.sigmoid(logit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR7FaNXOybJu"
      },
      "source": [
        "## Train our classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7JYZMxEybJx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3727889-d312-494b-a0d3-505f3fc9df8b"
      },
      "source": [
        "from transformers import BertModel, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassfication, the pretrained BERT model \n",
        "# with a single linear classification layer on top.\n",
        "bert_model = BertModel.from_pretrained(\"bert-base-uncased\", output_hidden_states = True) # whether the model returns all hidden states\n",
        "\n",
        "model = BertCNN(768, bert_model)\n",
        "\n",
        "# Tell PyTorch to run this model on the GPU\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertCNN(\n",
              "  (convs1): ModuleList(\n",
              "    (0): Conv2d(4, 32, kernel_size=(2, 768), stride=(1, 1))\n",
              "    (1): Conv2d(4, 32, kernel_size=(3, 768), stride=(1, 1))\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (fc1): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              "  (bert_model): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX9bftmNybJ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61ff1768-6b04-4e51-d10e-1cccdfa61cd3"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print(\"The BERT model has {:} different named parameters.\\n\".format(len(params)))\n",
        "print(\"=== Embedding Layer ===\\n\")\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print(\"\\n==== First Transformer ====\\n\")\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print(\"\\n==== Output Layer====\\n\")\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 205 different named parameters.\n",
            "\n",
            "=== Embedding Layer ===\n",
            "\n",
            "convs1.0.weight                                         (32, 4, 2, 768)\n",
            "convs1.0.bias                                                  (32,)\n",
            "convs1.1.weight                                         (32, 4, 3, 768)\n",
            "convs1.1.bias                                                  (32,)\n",
            "fc1.weight                                                   (1, 64)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "fc1.bias                                                        (1,)\n",
            "bert_model.embeddings.word_embeddings.weight            (30522, 768)\n",
            "bert_model.embeddings.position_embeddings.weight          (512, 768)\n",
            "bert_model.embeddings.token_type_embeddings.weight          (2, 768)\n",
            "bert_model.embeddings.LayerNorm.weight                        (768,)\n",
            "bert_model.embeddings.LayerNorm.bias                          (768,)\n",
            "bert_model.encoder.layer.0.attention.self.query.weight    (768, 768)\n",
            "bert_model.encoder.layer.0.attention.self.query.bias          (768,)\n",
            "bert_model.encoder.layer.0.attention.self.key.weight      (768, 768)\n",
            "bert_model.encoder.layer.0.attention.self.key.bias            (768,)\n",
            "bert_model.encoder.layer.0.attention.self.value.weight    (768, 768)\n",
            "bert_model.encoder.layer.0.attention.self.value.bias          (768,)\n",
            "bert_model.encoder.layer.0.attention.output.dense.weight   (768, 768)\n",
            "bert_model.encoder.layer.0.attention.output.dense.bias        (768,)\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n",
            "\n",
            "==== Output Layer====\n",
            "\n",
            "bert_model.encoder.layer.11.output.LayerNorm.weight           (768,)\n",
            "bert_model.encoder.layer.11.output.LayerNorm.bias             (768,)\n",
            "bert_model.pooler.dense.weight                            (768, 768)\n",
            "bert_model.pooler.dense.bias                                  (768,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN8StKalybJ5"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
        "# I believe the 'W' stands for \"Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvTMmRTvybJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd8f82f2-c208-47ce-8ed8-5d482e4ca171"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (we recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "print(len(train_dataloader))\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "288\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pigy1CqrybKA"
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=-1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXBpr-HAybKD"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Take a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round(elapsed))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0QRDrYcybKG"
      },
      "source": [
        "import random\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible\n",
        "def set_seed(seed_val):\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOCgIIrpybKI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "545898c0-fb34-40d3-cc1f-d7cee08472dc"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "seed_val = 42\n",
        "set_seed(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them\n",
        "loss_values = []\n",
        "\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "# For each epoch\n",
        "for epoch in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "    \n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch + 1, epochs))\n",
        "    print('Training...')\n",
        "    \n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "    \n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0.\n",
        "    \n",
        "    # Put the model into training mode.\n",
        "    # Don't be mislead -- the call to 'train' just changes the \"mode\", it doesn't \"perform\" the training.\n",
        "    # 'dropout' and 'bachnorm' layers behave differently during training vs test\n",
        "    model.train()\n",
        "    \n",
        "    # For each batch of training data\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        \n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress\n",
        "            print(\"Batch {:>5,} of {:>5,}. Elapsed: {:}.\".format(step, len(train_dataloader), elapsed))\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()\n",
        "        \n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, b_input_mask, token_type_ids=None)\n",
        "\n",
        "        print(\"outputs :\", outputs)\n",
        "\n",
        "        print(\"b_labels :\", b_labels.unsqueeze(1))\n",
        "\n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = loss_fn(outputs, b_labels.unsqueeze(1))\n",
        "        \n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value from the tensor.\n",
        "        total_loss += loss.item()\n",
        "        \n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "        \n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.        \n",
        "        optimizer.step()\n",
        "        \n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "    \n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "    \n",
        "    print(\"\")\n",
        "    print(\"Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
        "    \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on our validation set.\n",
        "    \n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "    \n",
        "    t0 = time.time()\n",
        "    \n",
        "    # Put the model in evaluation mode -- the dropout layers behave differently during evaluation\n",
        "    model.eval()\n",
        "    \n",
        "    # Tracking variables\n",
        "    eval_loss, eval_acc = 0., 0.\n",
        "    \n",
        "    \n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for valid_step, batch in enumerate(valid_dataloader):\n",
        "        \n",
        "        val_preds = []\n",
        "\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "        with torch.no_grad():\n",
        "            \n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have not provided labels.\n",
        "            outputs = model(b_input_ids, b_input_mask, token_type_ids=None)\n",
        "            \n",
        "        # Get the \"logits\" output by the model.\n",
        "        # The \"logits\" are the output values prior to applying an activation function like the softmax\n",
        "        loss = loss_fn(outputs, b_labels.unsqueeze(1))\n",
        "\n",
        "        outputs = outputs.cpu().numpy().flatten()\n",
        "        val_preds += [ int(p >= 0.5) for p in outputs ]\n",
        "        \n",
        "        # Move logits and labels to CPU\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_acc = flat_accuracy(val_preds, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_acc += tmp_eval_acc       \n",
        "    \n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"Accuracy: {0:.2f}\".format(eval_acc / (valid_step + 1)))\n",
        "    print(\"Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "        [0.9971],\n",
            "        [0.9981],\n",
            "        [0.9990],\n",
            "        [0.9982],\n",
            "        [0.9949]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9980],\n",
            "        [0.9968],\n",
            "        [0.9976],\n",
            "        [0.9975],\n",
            "        [0.9987],\n",
            "        [0.9988],\n",
            "        [0.9976],\n",
            "        [0.9990],\n",
            "        [0.9983],\n",
            "        [0.9482],\n",
            "        [0.9984],\n",
            "        [0.9995],\n",
            "        [0.9984],\n",
            "        [0.9902],\n",
            "        [0.9989],\n",
            "        [0.9989],\n",
            "        [0.9957],\n",
            "        [0.9994],\n",
            "        [0.9977],\n",
            "        [0.9984],\n",
            "        [0.9939],\n",
            "        [0.9989],\n",
            "        [0.9984],\n",
            "        [0.9944],\n",
            "        [0.9979],\n",
            "        [0.9987],\n",
            "        [0.9992],\n",
            "        [0.9941],\n",
            "        [0.9994],\n",
            "        [0.9987],\n",
            "        [0.9931],\n",
            "        [0.9996]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9988],\n",
            "        [0.9981],\n",
            "        [0.9982],\n",
            "        [0.9991],\n",
            "        [0.9938],\n",
            "        [0.9992],\n",
            "        [0.9971],\n",
            "        [0.9982],\n",
            "        [0.9981],\n",
            "        [0.9991],\n",
            "        [0.9992],\n",
            "        [0.9991],\n",
            "        [0.9263],\n",
            "        [0.9950],\n",
            "        [0.9986],\n",
            "        [0.7344],\n",
            "        [0.9987],\n",
            "        [0.9993],\n",
            "        [0.0068],\n",
            "        [0.9987],\n",
            "        [0.9982],\n",
            "        [0.9989],\n",
            "        [0.9994],\n",
            "        [0.9986],\n",
            "        [0.9993],\n",
            "        [0.9960],\n",
            "        [0.9991],\n",
            "        [0.0071],\n",
            "        [0.9994],\n",
            "        [0.9979],\n",
            "        [0.9990],\n",
            "        [0.9985]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9990],\n",
            "        [0.9977],\n",
            "        [0.9973],\n",
            "        [0.9985],\n",
            "        [0.9971],\n",
            "        [0.9886],\n",
            "        [0.9987],\n",
            "        [0.9989],\n",
            "        [0.0023],\n",
            "        [0.9965],\n",
            "        [0.9993],\n",
            "        [0.9949],\n",
            "        [0.9983],\n",
            "        [0.9957],\n",
            "        [0.9971],\n",
            "        [0.9981],\n",
            "        [0.9927],\n",
            "        [0.9915],\n",
            "        [0.0035],\n",
            "        [0.0040],\n",
            "        [0.9991],\n",
            "        [0.9983],\n",
            "        [0.9986],\n",
            "        [0.9995],\n",
            "        [0.9975],\n",
            "        [0.9944],\n",
            "        [0.9989],\n",
            "        [0.9989],\n",
            "        [0.9993],\n",
            "        [0.9991],\n",
            "        [0.9986],\n",
            "        [0.9989]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.1095],\n",
            "        [0.9987],\n",
            "        [0.9993],\n",
            "        [0.9976],\n",
            "        [0.9953],\n",
            "        [0.9993],\n",
            "        [0.9987],\n",
            "        [0.9965],\n",
            "        [0.9977],\n",
            "        [0.9980],\n",
            "        [0.9992],\n",
            "        [0.9994],\n",
            "        [0.9991],\n",
            "        [0.9978],\n",
            "        [0.9980],\n",
            "        [0.9993],\n",
            "        [0.9985],\n",
            "        [0.9944],\n",
            "        [0.9988],\n",
            "        [0.9980],\n",
            "        [0.9938],\n",
            "        [0.9975],\n",
            "        [0.9979],\n",
            "        [0.9972],\n",
            "        [0.9988],\n",
            "        [0.9946],\n",
            "        [0.9900],\n",
            "        [0.9980],\n",
            "        [0.9983],\n",
            "        [0.9986],\n",
            "        [0.9991],\n",
            "        [0.9952]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9990],\n",
            "        [0.9935],\n",
            "        [0.9934],\n",
            "        [0.9990],\n",
            "        [0.9963],\n",
            "        [0.0247],\n",
            "        [0.9992],\n",
            "        [0.9993],\n",
            "        [0.9984],\n",
            "        [0.9993],\n",
            "        [0.9984],\n",
            "        [0.9990],\n",
            "        [0.9989],\n",
            "        [0.9975],\n",
            "        [0.9972],\n",
            "        [0.9956],\n",
            "        [0.9983],\n",
            "        [0.9966],\n",
            "        [0.9992],\n",
            "        [0.9984],\n",
            "        [0.9961],\n",
            "        [0.9987],\n",
            "        [0.9894],\n",
            "        [0.9985],\n",
            "        [0.9709],\n",
            "        [0.9976],\n",
            "        [0.9910],\n",
            "        [0.9992],\n",
            "        [0.9993],\n",
            "        [0.9992],\n",
            "        [0.9951],\n",
            "        [0.9871]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9972],\n",
            "        [0.9973],\n",
            "        [0.9991],\n",
            "        [0.9971],\n",
            "        [0.9987],\n",
            "        [0.9986],\n",
            "        [0.9986],\n",
            "        [0.9984],\n",
            "        [0.9986],\n",
            "        [0.8575],\n",
            "        [0.9989],\n",
            "        [0.9984],\n",
            "        [0.9983],\n",
            "        [0.9981],\n",
            "        [0.9863],\n",
            "        [0.9990],\n",
            "        [0.9698],\n",
            "        [0.9957],\n",
            "        [0.0018],\n",
            "        [0.9941],\n",
            "        [0.9975],\n",
            "        [0.9988],\n",
            "        [0.9987],\n",
            "        [0.9984],\n",
            "        [0.9984],\n",
            "        [0.9991],\n",
            "        [0.9991],\n",
            "        [0.9713],\n",
            "        [0.9978],\n",
            "        [0.9967],\n",
            "        [0.9967],\n",
            "        [0.9982]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9983],\n",
            "        [0.9984],\n",
            "        [0.9995],\n",
            "        [0.9988],\n",
            "        [0.9988],\n",
            "        [0.9991],\n",
            "        [0.9968],\n",
            "        [0.9968],\n",
            "        [0.9987],\n",
            "        [0.9989],\n",
            "        [0.9911],\n",
            "        [0.9993],\n",
            "        [0.9994],\n",
            "        [0.9533],\n",
            "        [0.9990],\n",
            "        [0.9986],\n",
            "        [0.9955],\n",
            "        [0.9987],\n",
            "        [0.0034],\n",
            "        [0.9982],\n",
            "        [0.9983],\n",
            "        [0.9985],\n",
            "        [0.0116],\n",
            "        [0.9630],\n",
            "        [0.9989],\n",
            "        [0.9989],\n",
            "        [0.9983],\n",
            "        [0.9958],\n",
            "        [0.9988],\n",
            "        [0.0057],\n",
            "        [0.9989],\n",
            "        [0.9964]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9957],\n",
            "        [0.9898],\n",
            "        [0.9974],\n",
            "        [0.9983],\n",
            "        [0.9957],\n",
            "        [0.9991],\n",
            "        [0.9985],\n",
            "        [0.9902],\n",
            "        [0.9975],\n",
            "        [0.9993],\n",
            "        [0.9986],\n",
            "        [0.9975],\n",
            "        [0.9981],\n",
            "        [0.9986],\n",
            "        [0.9803],\n",
            "        [0.9961],\n",
            "        [0.9921],\n",
            "        [0.9990],\n",
            "        [0.9988],\n",
            "        [0.9977],\n",
            "        [0.9958],\n",
            "        [0.0032],\n",
            "        [0.9993],\n",
            "        [0.0092],\n",
            "        [0.9970],\n",
            "        [0.9993],\n",
            "        [0.9969],\n",
            "        [0.9991],\n",
            "        [0.9988],\n",
            "        [0.9971],\n",
            "        [0.9960],\n",
            "        [0.9926]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.0077],\n",
            "        [0.9989],\n",
            "        [0.9976],\n",
            "        [0.9964],\n",
            "        [0.9977],\n",
            "        [0.9995],\n",
            "        [0.9983],\n",
            "        [0.9979],\n",
            "        [0.9969],\n",
            "        [0.9976],\n",
            "        [0.9995],\n",
            "        [0.9987],\n",
            "        [0.9986],\n",
            "        [0.9990],\n",
            "        [0.9952],\n",
            "        [0.9980],\n",
            "        [0.9980],\n",
            "        [0.9953],\n",
            "        [0.9989],\n",
            "        [0.9951],\n",
            "        [0.9992],\n",
            "        [0.9988],\n",
            "        [0.9982],\n",
            "        [0.9992],\n",
            "        [0.9996],\n",
            "        [0.9972],\n",
            "        [0.9938],\n",
            "        [0.9990],\n",
            "        [0.9978],\n",
            "        [0.9991],\n",
            "        [0.9932],\n",
            "        [0.9990]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9977],\n",
            "        [0.9975],\n",
            "        [0.9992],\n",
            "        [0.9987],\n",
            "        [0.9994],\n",
            "        [0.9990],\n",
            "        [0.9969],\n",
            "        [0.9908],\n",
            "        [0.9965],\n",
            "        [0.9980],\n",
            "        [0.9988],\n",
            "        [0.9988],\n",
            "        [0.9994],\n",
            "        [0.9971],\n",
            "        [0.9969],\n",
            "        [0.9986],\n",
            "        [0.9986],\n",
            "        [0.9989],\n",
            "        [0.9991],\n",
            "        [0.9972],\n",
            "        [0.9992],\n",
            "        [0.9996],\n",
            "        [0.9966],\n",
            "        [0.0027],\n",
            "        [0.9981],\n",
            "        [0.9976],\n",
            "        [0.9986],\n",
            "        [0.9982],\n",
            "        [0.9995],\n",
            "        [0.9994],\n",
            "        [0.9977],\n",
            "        [0.9950]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9984],\n",
            "        [0.9969],\n",
            "        [0.9910],\n",
            "        [0.9988],\n",
            "        [0.9988],\n",
            "        [0.9967],\n",
            "        [0.9979],\n",
            "        [0.9986],\n",
            "        [0.9968],\n",
            "        [0.9951],\n",
            "        [0.9990],\n",
            "        [0.9966],\n",
            "        [0.9991],\n",
            "        [0.8015],\n",
            "        [0.9991],\n",
            "        [0.2516],\n",
            "        [0.9962],\n",
            "        [0.9989],\n",
            "        [0.9977],\n",
            "        [0.9985],\n",
            "        [0.9985],\n",
            "        [0.9987],\n",
            "        [0.9964],\n",
            "        [0.9965],\n",
            "        [0.9985],\n",
            "        [0.9990],\n",
            "        [0.9935],\n",
            "        [0.9992],\n",
            "        [0.9970],\n",
            "        [0.9968],\n",
            "        [0.9983],\n",
            "        [0.9988]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9970],\n",
            "        [0.9973],\n",
            "        [0.9993],\n",
            "        [0.9966],\n",
            "        [0.9985],\n",
            "        [0.9990],\n",
            "        [0.9893],\n",
            "        [0.9984],\n",
            "        [0.9978],\n",
            "        [0.9985],\n",
            "        [0.9980],\n",
            "        [0.9990],\n",
            "        [0.9993],\n",
            "        [0.9929],\n",
            "        [0.9991],\n",
            "        [0.9983],\n",
            "        [0.9980],\n",
            "        [0.9989],\n",
            "        [0.9972],\n",
            "        [0.9981],\n",
            "        [0.9974],\n",
            "        [0.9979],\n",
            "        [0.9992],\n",
            "        [0.9976],\n",
            "        [0.9989],\n",
            "        [0.9994],\n",
            "        [0.9986],\n",
            "        [0.9988],\n",
            "        [0.9983],\n",
            "        [0.9994],\n",
            "        [0.0102],\n",
            "        [0.9992]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.0143],\n",
            "        [0.9995],\n",
            "        [0.9993],\n",
            "        [0.9979],\n",
            "        [0.9985],\n",
            "        [0.9981],\n",
            "        [0.9992],\n",
            "        [0.9990],\n",
            "        [0.9973],\n",
            "        [0.9964],\n",
            "        [0.9983],\n",
            "        [0.9990],\n",
            "        [0.9986],\n",
            "        [0.9983],\n",
            "        [0.9989],\n",
            "        [0.9994],\n",
            "        [0.9979],\n",
            "        [0.9924],\n",
            "        [0.9995],\n",
            "        [0.9992],\n",
            "        [0.9987],\n",
            "        [0.9981],\n",
            "        [0.9982],\n",
            "        [0.9991],\n",
            "        [0.9984],\n",
            "        [0.9990],\n",
            "        [0.9987],\n",
            "        [0.9978],\n",
            "        [0.9979],\n",
            "        [0.9979],\n",
            "        [0.9992],\n",
            "        [0.9984]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9979],\n",
            "        [0.9992],\n",
            "        [0.9993],\n",
            "        [0.9952],\n",
            "        [0.9978],\n",
            "        [0.9990],\n",
            "        [0.9967],\n",
            "        [0.9935],\n",
            "        [0.9994],\n",
            "        [0.9991],\n",
            "        [0.9985],\n",
            "        [0.0479],\n",
            "        [0.9971],\n",
            "        [0.9992],\n",
            "        [0.9994],\n",
            "        [0.9973],\n",
            "        [0.9973],\n",
            "        [0.0041],\n",
            "        [0.9983],\n",
            "        [0.9967],\n",
            "        [0.9985],\n",
            "        [0.9985],\n",
            "        [0.9991],\n",
            "        [0.9992],\n",
            "        [0.9988],\n",
            "        [0.9982],\n",
            "        [0.9927],\n",
            "        [0.9982],\n",
            "        [0.9792],\n",
            "        [0.9990],\n",
            "        [0.9979],\n",
            "        [0.9992]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9988],\n",
            "        [0.9968],\n",
            "        [0.8176],\n",
            "        [0.0017],\n",
            "        [0.9981],\n",
            "        [0.9980],\n",
            "        [0.9990],\n",
            "        [0.9962],\n",
            "        [0.9981],\n",
            "        [0.9945],\n",
            "        [0.9941],\n",
            "        [0.9992],\n",
            "        [0.0055],\n",
            "        [0.0049],\n",
            "        [0.9988],\n",
            "        [0.9990],\n",
            "        [0.9993],\n",
            "        [0.9987],\n",
            "        [0.9956],\n",
            "        [0.9977],\n",
            "        [0.9984],\n",
            "        [0.9987],\n",
            "        [0.9971],\n",
            "        [0.9965],\n",
            "        [0.4269],\n",
            "        [0.9986],\n",
            "        [0.9989],\n",
            "        [0.9790],\n",
            "        [0.9976],\n",
            "        [0.9964],\n",
            "        [0.9982],\n",
            "        [0.9948]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9988],\n",
            "        [0.9825],\n",
            "        [0.9982],\n",
            "        [0.0232],\n",
            "        [0.9990],\n",
            "        [0.9984],\n",
            "        [0.9988],\n",
            "        [0.9984],\n",
            "        [0.9988],\n",
            "        [0.9985],\n",
            "        [0.9965],\n",
            "        [0.9945],\n",
            "        [0.9982],\n",
            "        [0.9985],\n",
            "        [0.9933],\n",
            "        [0.9975],\n",
            "        [0.9995],\n",
            "        [0.9982],\n",
            "        [0.9985],\n",
            "        [0.9994],\n",
            "        [0.9990],\n",
            "        [0.9995],\n",
            "        [0.9933],\n",
            "        [0.9969],\n",
            "        [0.9994],\n",
            "        [0.9972],\n",
            "        [0.9991],\n",
            "        [0.9993],\n",
            "        [0.9995],\n",
            "        [0.9989],\n",
            "        [0.9985],\n",
            "        [0.9874]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9959],\n",
            "        [0.9989],\n",
            "        [0.9992],\n",
            "        [0.9982],\n",
            "        [0.9995],\n",
            "        [0.9882],\n",
            "        [0.9984],\n",
            "        [0.9980],\n",
            "        [0.9971],\n",
            "        [0.9956],\n",
            "        [0.9977],\n",
            "        [0.9974],\n",
            "        [0.9995],\n",
            "        [0.9982],\n",
            "        [0.9954],\n",
            "        [0.9988],\n",
            "        [0.9902],\n",
            "        [0.9969],\n",
            "        [0.9973],\n",
            "        [0.9977],\n",
            "        [0.9986],\n",
            "        [0.9721],\n",
            "        [0.9981],\n",
            "        [0.9984],\n",
            "        [0.9973],\n",
            "        [0.9949],\n",
            "        [0.9974],\n",
            "        [0.9972],\n",
            "        [0.9986],\n",
            "        [0.9993],\n",
            "        [0.9992],\n",
            "        [0.9986]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9913],\n",
            "        [0.9977],\n",
            "        [0.9986],\n",
            "        [0.9989],\n",
            "        [0.9977],\n",
            "        [0.9969],\n",
            "        [0.9985],\n",
            "        [0.0658],\n",
            "        [0.9936],\n",
            "        [0.9993],\n",
            "        [0.0058],\n",
            "        [0.9982],\n",
            "        [0.9872],\n",
            "        [0.9990],\n",
            "        [0.9970],\n",
            "        [0.9966],\n",
            "        [0.9887],\n",
            "        [0.9993],\n",
            "        [0.9978],\n",
            "        [0.9974],\n",
            "        [0.9993],\n",
            "        [0.9991],\n",
            "        [0.9995],\n",
            "        [0.9991],\n",
            "        [0.9993],\n",
            "        [0.9988],\n",
            "        [0.9934],\n",
            "        [0.9968],\n",
            "        [0.9993],\n",
            "        [0.0025],\n",
            "        [0.9964],\n",
            "        [0.9068]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9973],\n",
            "        [0.9881],\n",
            "        [0.0100],\n",
            "        [0.9823],\n",
            "        [0.9994],\n",
            "        [0.9981],\n",
            "        [0.9987],\n",
            "        [0.9973],\n",
            "        [0.9951],\n",
            "        [0.9990],\n",
            "        [0.9988],\n",
            "        [0.9993],\n",
            "        [0.9988],\n",
            "        [0.0027],\n",
            "        [0.9975],\n",
            "        [0.9963],\n",
            "        [0.9984],\n",
            "        [0.9993],\n",
            "        [0.0044],\n",
            "        [0.9973],\n",
            "        [0.9961],\n",
            "        [0.9975],\n",
            "        [0.9986],\n",
            "        [0.9956],\n",
            "        [0.9980],\n",
            "        [0.9991],\n",
            "        [0.9993],\n",
            "        [0.9963],\n",
            "        [0.9969],\n",
            "        [0.0033],\n",
            "        [0.9992],\n",
            "        [0.9975]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9893],\n",
            "        [0.9977],\n",
            "        [0.9989],\n",
            "        [0.9988],\n",
            "        [0.9855],\n",
            "        [0.9980],\n",
            "        [0.9987],\n",
            "        [0.9967],\n",
            "        [0.9977],\n",
            "        [0.0022],\n",
            "        [0.9991],\n",
            "        [0.9992],\n",
            "        [0.9976],\n",
            "        [0.9990],\n",
            "        [0.9994],\n",
            "        [0.9993],\n",
            "        [0.9976],\n",
            "        [0.9983],\n",
            "        [0.9908],\n",
            "        [0.9974],\n",
            "        [0.9989],\n",
            "        [0.9984],\n",
            "        [0.9985],\n",
            "        [0.9966],\n",
            "        [0.9987],\n",
            "        [0.9989],\n",
            "        [0.9991],\n",
            "        [0.0021],\n",
            "        [0.9949],\n",
            "        [0.0089],\n",
            "        [0.9955],\n",
            "        [0.9984]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9932],\n",
            "        [0.9979],\n",
            "        [0.9988],\n",
            "        [0.9988],\n",
            "        [0.9984],\n",
            "        [0.9981],\n",
            "        [0.9990],\n",
            "        [0.9991],\n",
            "        [0.0130],\n",
            "        [0.9993],\n",
            "        [0.9973],\n",
            "        [0.9961],\n",
            "        [0.9949],\n",
            "        [0.9959],\n",
            "        [0.9968],\n",
            "        [0.9985],\n",
            "        [0.9936],\n",
            "        [0.9979],\n",
            "        [0.9989],\n",
            "        [0.9988],\n",
            "        [0.9983],\n",
            "        [0.9991],\n",
            "        [0.9988],\n",
            "        [0.8455],\n",
            "        [0.9987],\n",
            "        [0.9981],\n",
            "        [0.9968],\n",
            "        [0.9972],\n",
            "        [0.9943],\n",
            "        [0.9968],\n",
            "        [0.9923],\n",
            "        [0.9983]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9978],\n",
            "        [0.9980],\n",
            "        [0.9929],\n",
            "        [0.9988],\n",
            "        [0.9994],\n",
            "        [0.9984],\n",
            "        [0.9987],\n",
            "        [0.9971],\n",
            "        [0.9989],\n",
            "        [0.9948],\n",
            "        [0.9992],\n",
            "        [0.9954],\n",
            "        [0.9993],\n",
            "        [0.9979],\n",
            "        [0.9967],\n",
            "        [0.9981],\n",
            "        [0.9921],\n",
            "        [0.9967],\n",
            "        [0.9991],\n",
            "        [0.9988],\n",
            "        [0.9981],\n",
            "        [0.9995],\n",
            "        [0.9977],\n",
            "        [0.9986],\n",
            "        [0.9769],\n",
            "        [0.9990],\n",
            "        [0.9966],\n",
            "        [0.9984],\n",
            "        [0.9966],\n",
            "        [0.9985],\n",
            "        [0.9989],\n",
            "        [0.9951]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9983],\n",
            "        [0.9973],\n",
            "        [0.9942],\n",
            "        [0.9980],\n",
            "        [0.9976],\n",
            "        [0.9988],\n",
            "        [0.9990],\n",
            "        [0.9992],\n",
            "        [0.9986],\n",
            "        [0.9928],\n",
            "        [0.9986],\n",
            "        [0.9989],\n",
            "        [0.8884],\n",
            "        [0.9988],\n",
            "        [0.9993],\n",
            "        [0.9978],\n",
            "        [0.9993],\n",
            "        [0.9986],\n",
            "        [0.9981],\n",
            "        [0.9989],\n",
            "        [0.9986],\n",
            "        [0.9981],\n",
            "        [0.9987],\n",
            "        [0.9952],\n",
            "        [0.9989],\n",
            "        [0.9988],\n",
            "        [0.9976],\n",
            "        [0.9994],\n",
            "        [0.9994],\n",
            "        [0.9983],\n",
            "        [0.9987],\n",
            "        [0.9994]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9986],\n",
            "        [0.9992],\n",
            "        [0.9993],\n",
            "        [0.9952],\n",
            "        [0.9986],\n",
            "        [0.0164],\n",
            "        [0.9984],\n",
            "        [0.9992],\n",
            "        [0.9948],\n",
            "        [0.9988],\n",
            "        [0.9992],\n",
            "        [0.9991],\n",
            "        [0.9988],\n",
            "        [0.9988],\n",
            "        [0.9975],\n",
            "        [0.0040],\n",
            "        [0.9989],\n",
            "        [0.9977],\n",
            "        [0.9982],\n",
            "        [0.0130],\n",
            "        [0.0025],\n",
            "        [0.9968],\n",
            "        [0.9982],\n",
            "        [0.9983],\n",
            "        [0.9977],\n",
            "        [0.9992],\n",
            "        [0.9984],\n",
            "        [0.9976],\n",
            "        [0.9979],\n",
            "        [0.9990],\n",
            "        [0.9970],\n",
            "        [0.9977]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9993],\n",
            "        [0.9990],\n",
            "        [0.9786],\n",
            "        [0.9967],\n",
            "        [0.9984],\n",
            "        [0.9992],\n",
            "        [0.9917],\n",
            "        [0.9982],\n",
            "        [0.9978],\n",
            "        [0.9993],\n",
            "        [0.9930],\n",
            "        [0.9988],\n",
            "        [0.9992],\n",
            "        [0.9994],\n",
            "        [0.9947],\n",
            "        [0.9991],\n",
            "        [0.9966],\n",
            "        [0.9989],\n",
            "        [0.9990],\n",
            "        [0.9993],\n",
            "        [0.9982],\n",
            "        [0.9975],\n",
            "        [0.9978],\n",
            "        [0.9971],\n",
            "        [0.9991],\n",
            "        [0.9993],\n",
            "        [0.9943],\n",
            "        [0.9975],\n",
            "        [0.9931],\n",
            "        [0.9991],\n",
            "        [0.9974],\n",
            "        [0.9948]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9992],\n",
            "        [0.9984],\n",
            "        [0.9978],\n",
            "        [0.9968],\n",
            "        [0.9973],\n",
            "        [0.9984],\n",
            "        [0.9989],\n",
            "        [0.9980],\n",
            "        [0.9992],\n",
            "        [0.9970],\n",
            "        [0.0049],\n",
            "        [0.9980],\n",
            "        [0.9988],\n",
            "        [0.9972],\n",
            "        [0.9909],\n",
            "        [0.9983],\n",
            "        [0.9913],\n",
            "        [0.9985],\n",
            "        [0.9927],\n",
            "        [0.9990],\n",
            "        [0.9979],\n",
            "        [0.9981],\n",
            "        [0.9992],\n",
            "        [0.9978],\n",
            "        [0.9984],\n",
            "        [0.0043],\n",
            "        [0.9986],\n",
            "        [0.9946],\n",
            "        [0.9991],\n",
            "        [0.9995],\n",
            "        [0.9942],\n",
            "        [0.9942]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9985],\n",
            "        [0.9972],\n",
            "        [0.9972],\n",
            "        [0.9987],\n",
            "        [0.9981],\n",
            "        [0.9983],\n",
            "        [0.0797],\n",
            "        [0.9964],\n",
            "        [0.9994],\n",
            "        [0.9985],\n",
            "        [0.9987],\n",
            "        [0.9988],\n",
            "        [0.9973],\n",
            "        [0.9992],\n",
            "        [0.9970],\n",
            "        [0.9974],\n",
            "        [0.9989],\n",
            "        [0.9980],\n",
            "        [0.9990],\n",
            "        [0.9912],\n",
            "        [0.9984],\n",
            "        [0.9283],\n",
            "        [0.9974],\n",
            "        [0.9982],\n",
            "        [0.9952],\n",
            "        [0.9973],\n",
            "        [0.9995],\n",
            "        [0.9979],\n",
            "        [0.9963],\n",
            "        [0.7802],\n",
            "        [0.9990],\n",
            "        [0.9991]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9927],\n",
            "        [0.9826],\n",
            "        [0.9989],\n",
            "        [0.9971],\n",
            "        [0.9990],\n",
            "        [0.9965],\n",
            "        [0.9897],\n",
            "        [0.9992],\n",
            "        [0.0036],\n",
            "        [0.9994],\n",
            "        [0.9991],\n",
            "        [0.9977],\n",
            "        [0.9926],\n",
            "        [0.9977],\n",
            "        [0.9970],\n",
            "        [0.9720],\n",
            "        [0.9987],\n",
            "        [0.9986],\n",
            "        [0.9983],\n",
            "        [0.9971],\n",
            "        [0.9928],\n",
            "        [0.9988],\n",
            "        [0.9920],\n",
            "        [0.9992],\n",
            "        [0.9992],\n",
            "        [0.0058],\n",
            "        [0.9957],\n",
            "        [0.9976],\n",
            "        [0.9978],\n",
            "        [0.9974],\n",
            "        [0.9980],\n",
            "        [0.9992]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9994],\n",
            "        [0.9975],\n",
            "        [0.9987],\n",
            "        [0.9977],\n",
            "        [0.9991],\n",
            "        [0.9984],\n",
            "        [0.9989],\n",
            "        [0.9983],\n",
            "        [0.9980],\n",
            "        [0.9745],\n",
            "        [0.9973],\n",
            "        [0.9979],\n",
            "        [0.9993],\n",
            "        [0.9968],\n",
            "        [0.9977],\n",
            "        [0.9990],\n",
            "        [0.9987],\n",
            "        [0.9981],\n",
            "        [0.0034],\n",
            "        [0.9993],\n",
            "        [0.9988],\n",
            "        [0.9959],\n",
            "        [0.9980],\n",
            "        [0.9992],\n",
            "        [0.9989],\n",
            "        [0.9992],\n",
            "        [0.9986],\n",
            "        [0.9989],\n",
            "        [0.9987],\n",
            "        [0.9985],\n",
            "        [0.9985],\n",
            "        [0.9939]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.7283],\n",
            "        [0.0029],\n",
            "        [0.9867],\n",
            "        [0.9991],\n",
            "        [0.9967],\n",
            "        [0.9852],\n",
            "        [0.9985],\n",
            "        [0.9988],\n",
            "        [0.9993],\n",
            "        [0.9992],\n",
            "        [0.9970],\n",
            "        [0.9995],\n",
            "        [0.9992],\n",
            "        [0.9984],\n",
            "        [0.9982],\n",
            "        [0.0017],\n",
            "        [0.9980],\n",
            "        [0.9607],\n",
            "        [0.9987],\n",
            "        [0.9984],\n",
            "        [0.9978],\n",
            "        [0.9987],\n",
            "        [0.0048],\n",
            "        [0.9981],\n",
            "        [0.9982],\n",
            "        [0.9986],\n",
            "        [0.9973],\n",
            "        [0.9989],\n",
            "        [0.9993],\n",
            "        [0.9941],\n",
            "        [0.9961],\n",
            "        [0.0248]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.]], device='cuda:0')\n",
            "Batch   240 of   288. Elapsed: 0:01:29.\n",
            "outputs : tensor([[0.9985],\n",
            "        [0.9974],\n",
            "        [0.9960],\n",
            "        [0.9990],\n",
            "        [0.9971],\n",
            "        [0.9987],\n",
            "        [0.9934],\n",
            "        [0.9957],\n",
            "        [0.9994],\n",
            "        [0.9994],\n",
            "        [0.9985],\n",
            "        [0.9984],\n",
            "        [0.9686],\n",
            "        [0.9988],\n",
            "        [0.9977],\n",
            "        [0.9971],\n",
            "        [0.9990],\n",
            "        [0.9970],\n",
            "        [0.9986],\n",
            "        [0.9985],\n",
            "        [0.9979],\n",
            "        [0.9987],\n",
            "        [0.9960],\n",
            "        [0.9991],\n",
            "        [0.9982],\n",
            "        [0.9988],\n",
            "        [0.9985],\n",
            "        [0.0357],\n",
            "        [0.9992],\n",
            "        [0.9986],\n",
            "        [0.9977],\n",
            "        [0.9981]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9977],\n",
            "        [0.9989],\n",
            "        [0.9979],\n",
            "        [0.9986],\n",
            "        [0.0040],\n",
            "        [0.9980],\n",
            "        [0.9880],\n",
            "        [0.9969],\n",
            "        [0.9984],\n",
            "        [0.9964],\n",
            "        [0.9987],\n",
            "        [0.0031],\n",
            "        [0.9975],\n",
            "        [0.9995],\n",
            "        [0.9811],\n",
            "        [0.9951],\n",
            "        [0.9986],\n",
            "        [0.9990],\n",
            "        [0.9987],\n",
            "        [0.9952],\n",
            "        [0.9990],\n",
            "        [0.9982],\n",
            "        [0.9980],\n",
            "        [0.9991],\n",
            "        [0.9959],\n",
            "        [0.9994],\n",
            "        [0.9968],\n",
            "        [0.9955],\n",
            "        [0.9975],\n",
            "        [0.4915],\n",
            "        [0.9979],\n",
            "        [0.9990]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9914],\n",
            "        [0.9995],\n",
            "        [0.9855],\n",
            "        [0.9964],\n",
            "        [0.9994],\n",
            "        [0.9959],\n",
            "        [0.9980],\n",
            "        [0.9981],\n",
            "        [0.9986],\n",
            "        [0.9984],\n",
            "        [0.9993],\n",
            "        [0.9988],\n",
            "        [0.9981],\n",
            "        [0.9983],\n",
            "        [0.9993],\n",
            "        [0.9909],\n",
            "        [0.9979],\n",
            "        [0.9983],\n",
            "        [0.9987],\n",
            "        [0.9985],\n",
            "        [0.9966],\n",
            "        [0.9993],\n",
            "        [0.9961],\n",
            "        [0.9991],\n",
            "        [0.9948],\n",
            "        [0.9990],\n",
            "        [0.9988],\n",
            "        [0.9988],\n",
            "        [0.0168],\n",
            "        [0.9984],\n",
            "        [0.9929],\n",
            "        [0.9989]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9993],\n",
            "        [0.9983],\n",
            "        [0.9968],\n",
            "        [0.9979],\n",
            "        [0.9990],\n",
            "        [0.9983],\n",
            "        [0.9987],\n",
            "        [0.9975],\n",
            "        [0.9992],\n",
            "        [0.9969],\n",
            "        [0.0121],\n",
            "        [0.9981],\n",
            "        [0.9948],\n",
            "        [0.9991],\n",
            "        [0.9976],\n",
            "        [0.9992],\n",
            "        [0.9955],\n",
            "        [0.9988],\n",
            "        [0.9984],\n",
            "        [0.9955],\n",
            "        [0.9971],\n",
            "        [0.9992],\n",
            "        [0.2978],\n",
            "        [0.9992],\n",
            "        [0.9990],\n",
            "        [0.0055],\n",
            "        [0.9995],\n",
            "        [0.9991],\n",
            "        [0.9984],\n",
            "        [0.9983],\n",
            "        [0.9968],\n",
            "        [0.9994]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9980],\n",
            "        [0.9977],\n",
            "        [0.9983],\n",
            "        [0.9985],\n",
            "        [0.9974],\n",
            "        [0.9990],\n",
            "        [0.9976],\n",
            "        [0.9841],\n",
            "        [0.9986],\n",
            "        [0.9978],\n",
            "        [0.9953],\n",
            "        [0.9959],\n",
            "        [0.9967],\n",
            "        [0.9959],\n",
            "        [0.9845],\n",
            "        [0.9989],\n",
            "        [0.9978],\n",
            "        [0.9944],\n",
            "        [0.9906],\n",
            "        [0.9946],\n",
            "        [0.9950],\n",
            "        [0.9975],\n",
            "        [0.9987],\n",
            "        [0.9995],\n",
            "        [0.9974],\n",
            "        [0.0435],\n",
            "        [0.9964],\n",
            "        [0.9995],\n",
            "        [0.9994],\n",
            "        [0.9984],\n",
            "        [0.9986],\n",
            "        [0.9984]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9990],\n",
            "        [0.9983],\n",
            "        [0.9957],\n",
            "        [0.9982],\n",
            "        [0.9958],\n",
            "        [0.9960],\n",
            "        [0.9964],\n",
            "        [0.9980],\n",
            "        [0.9992],\n",
            "        [0.9995],\n",
            "        [0.9994],\n",
            "        [0.9989],\n",
            "        [0.9989],\n",
            "        [0.0027],\n",
            "        [0.9995],\n",
            "        [0.9992],\n",
            "        [0.9957],\n",
            "        [0.9977],\n",
            "        [0.9952],\n",
            "        [0.9962],\n",
            "        [0.9976],\n",
            "        [0.9972],\n",
            "        [0.9972],\n",
            "        [0.9975],\n",
            "        [0.9931],\n",
            "        [0.9993],\n",
            "        [0.9994],\n",
            "        [0.9981],\n",
            "        [0.9991],\n",
            "        [0.9966],\n",
            "        [0.0345],\n",
            "        [0.9993]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9991],\n",
            "        [0.9989],\n",
            "        [0.9966],\n",
            "        [0.9988],\n",
            "        [0.9988],\n",
            "        [0.9993],\n",
            "        [0.9989],\n",
            "        [0.9983],\n",
            "        [0.9990],\n",
            "        [0.9986],\n",
            "        [0.9979],\n",
            "        [0.9991],\n",
            "        [0.9972],\n",
            "        [0.9972],\n",
            "        [0.9989],\n",
            "        [0.9994],\n",
            "        [0.9994],\n",
            "        [0.9985],\n",
            "        [0.9934],\n",
            "        [0.9982],\n",
            "        [0.9987],\n",
            "        [0.9978],\n",
            "        [0.9925],\n",
            "        [0.9984],\n",
            "        [0.9987],\n",
            "        [0.9980],\n",
            "        [0.9935],\n",
            "        [0.9990],\n",
            "        [0.9983],\n",
            "        [0.9980],\n",
            "        [0.9988],\n",
            "        [0.9989]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9988],\n",
            "        [0.9619],\n",
            "        [0.9994],\n",
            "        [0.0380],\n",
            "        [0.9980],\n",
            "        [0.9991],\n",
            "        [0.9978],\n",
            "        [0.9969],\n",
            "        [0.9991],\n",
            "        [0.0046],\n",
            "        [0.9993],\n",
            "        [0.9932],\n",
            "        [0.9900],\n",
            "        [0.0146],\n",
            "        [0.9960],\n",
            "        [0.9989],\n",
            "        [0.9994],\n",
            "        [0.9994],\n",
            "        [0.9987],\n",
            "        [0.9995],\n",
            "        [0.0050],\n",
            "        [0.9972],\n",
            "        [0.9979],\n",
            "        [0.9949],\n",
            "        [0.9921],\n",
            "        [0.9987],\n",
            "        [0.0062],\n",
            "        [0.9952],\n",
            "        [0.9990],\n",
            "        [0.9995],\n",
            "        [0.9986],\n",
            "        [0.9982]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9955],\n",
            "        [0.9985],\n",
            "        [0.9984],\n",
            "        [0.9636],\n",
            "        [0.9991],\n",
            "        [0.9986],\n",
            "        [0.9979],\n",
            "        [0.0031],\n",
            "        [0.9990],\n",
            "        [0.9978],\n",
            "        [0.9822],\n",
            "        [0.9992],\n",
            "        [0.9991],\n",
            "        [0.9981],\n",
            "        [0.9996],\n",
            "        [0.9995],\n",
            "        [0.9993],\n",
            "        [0.9992],\n",
            "        [0.9974],\n",
            "        [0.9966],\n",
            "        [0.9976],\n",
            "        [0.9985],\n",
            "        [0.9953],\n",
            "        [0.9985],\n",
            "        [0.9960],\n",
            "        [0.0038],\n",
            "        [0.9983],\n",
            "        [0.9957],\n",
            "        [0.9978],\n",
            "        [0.9990],\n",
            "        [0.9990],\n",
            "        [0.9977]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9979],\n",
            "        [0.9983],\n",
            "        [0.9926],\n",
            "        [0.9942],\n",
            "        [0.9984],\n",
            "        [0.9989],\n",
            "        [0.0021],\n",
            "        [0.9990],\n",
            "        [0.9984],\n",
            "        [0.9938],\n",
            "        [0.9990],\n",
            "        [0.9964],\n",
            "        [0.9989],\n",
            "        [0.9960],\n",
            "        [0.9979],\n",
            "        [0.9942],\n",
            "        [0.9971],\n",
            "        [0.9992],\n",
            "        [0.9980],\n",
            "        [0.9884],\n",
            "        [0.9995],\n",
            "        [0.9934],\n",
            "        [0.9987],\n",
            "        [0.9991],\n",
            "        [0.9946],\n",
            "        [0.9979],\n",
            "        [0.9979],\n",
            "        [0.9924],\n",
            "        [0.9974],\n",
            "        [0.9969],\n",
            "        [0.9985],\n",
            "        [0.9956]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9978],\n",
            "        [0.9972],\n",
            "        [0.9980],\n",
            "        [0.9979],\n",
            "        [0.9983],\n",
            "        [0.9991],\n",
            "        [0.0225],\n",
            "        [0.9763],\n",
            "        [0.9977],\n",
            "        [0.9993],\n",
            "        [0.9973],\n",
            "        [0.9974],\n",
            "        [0.9971],\n",
            "        [0.9989],\n",
            "        [0.9981],\n",
            "        [0.9991],\n",
            "        [0.9973],\n",
            "        [0.9990],\n",
            "        [0.9979],\n",
            "        [0.9888],\n",
            "        [0.9979],\n",
            "        [0.9977],\n",
            "        [0.9983],\n",
            "        [0.9913],\n",
            "        [0.9986],\n",
            "        [0.9944],\n",
            "        [0.9989],\n",
            "        [0.9992],\n",
            "        [0.9975],\n",
            "        [0.9983],\n",
            "        [0.9991],\n",
            "        [0.9994]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9983],\n",
            "        [0.9987],\n",
            "        [0.9992],\n",
            "        [0.0033],\n",
            "        [0.9982],\n",
            "        [0.0022],\n",
            "        [0.9982],\n",
            "        [0.9987],\n",
            "        [0.9992],\n",
            "        [0.9994],\n",
            "        [0.9989],\n",
            "        [0.9986],\n",
            "        [0.9977],\n",
            "        [0.9942],\n",
            "        [0.9869],\n",
            "        [0.9947],\n",
            "        [0.9515],\n",
            "        [0.9990],\n",
            "        [0.9960],\n",
            "        [0.9986],\n",
            "        [0.9973],\n",
            "        [0.9958],\n",
            "        [0.9987],\n",
            "        [0.9986],\n",
            "        [0.9989],\n",
            "        [0.9955],\n",
            "        [0.9985],\n",
            "        [0.9982],\n",
            "        [0.8035],\n",
            "        [0.9994],\n",
            "        [0.9978],\n",
            "        [0.9987]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9973],\n",
            "        [0.9975],\n",
            "        [0.9992],\n",
            "        [0.9992],\n",
            "        [0.9975],\n",
            "        [0.9994],\n",
            "        [0.9984],\n",
            "        [0.9934],\n",
            "        [0.9968],\n",
            "        [0.9985],\n",
            "        [0.9971],\n",
            "        [0.9993],\n",
            "        [0.9991],\n",
            "        [0.0104],\n",
            "        [0.9984],\n",
            "        [0.9994],\n",
            "        [0.9991],\n",
            "        [0.9991],\n",
            "        [0.0015],\n",
            "        [0.9994],\n",
            "        [0.9959],\n",
            "        [0.9966],\n",
            "        [0.9992],\n",
            "        [0.9985],\n",
            "        [0.9992],\n",
            "        [0.9993],\n",
            "        [0.0046],\n",
            "        [0.9981],\n",
            "        [0.0019],\n",
            "        [0.9955],\n",
            "        [0.3813],\n",
            "        [0.9851]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9906],\n",
            "        [0.9987],\n",
            "        [0.9990],\n",
            "        [0.9986],\n",
            "        [0.9958],\n",
            "        [0.9958],\n",
            "        [0.9983],\n",
            "        [0.9993],\n",
            "        [0.9982],\n",
            "        [0.9966],\n",
            "        [0.9990],\n",
            "        [0.9958],\n",
            "        [0.9983],\n",
            "        [0.9988],\n",
            "        [0.9942],\n",
            "        [0.9987],\n",
            "        [0.9993],\n",
            "        [0.9982],\n",
            "        [0.0973],\n",
            "        [0.9974],\n",
            "        [0.9979],\n",
            "        [0.9940],\n",
            "        [0.9975],\n",
            "        [0.0079],\n",
            "        [0.9962],\n",
            "        [0.9992],\n",
            "        [0.9987],\n",
            "        [0.9958],\n",
            "        [0.9989],\n",
            "        [0.9988],\n",
            "        [0.0042],\n",
            "        [0.2623]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.]], device='cuda:0')\n",
            "outputs : tensor([[0.9995],\n",
            "        [0.9972],\n",
            "        [0.9987],\n",
            "        [0.9987],\n",
            "        [0.9598],\n",
            "        [0.9994],\n",
            "        [0.9956],\n",
            "        [0.2248],\n",
            "        [0.9976],\n",
            "        [0.9982],\n",
            "        [0.9970],\n",
            "        [0.9995],\n",
            "        [0.9955],\n",
            "        [0.9942],\n",
            "        [0.9993],\n",
            "        [0.9990],\n",
            "        [0.9984],\n",
            "        [0.9993],\n",
            "        [0.9986],\n",
            "        [0.9971],\n",
            "        [0.9973],\n",
            "        [0.9993],\n",
            "        [0.9908],\n",
            "        [0.9993],\n",
            "        [0.9989],\n",
            "        [0.9943],\n",
            "        [0.9954],\n",
            "        [0.9928],\n",
            "        [0.9990],\n",
            "        [0.9991],\n",
            "        [0.9981],\n",
            "        [0.9979]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9988],\n",
            "        [0.9978],\n",
            "        [0.9983],\n",
            "        [0.9966],\n",
            "        [0.5215],\n",
            "        [0.9990],\n",
            "        [0.9965],\n",
            "        [0.9986],\n",
            "        [0.9990],\n",
            "        [0.9981],\n",
            "        [0.2948],\n",
            "        [0.9982],\n",
            "        [0.0049],\n",
            "        [0.9940],\n",
            "        [0.9985],\n",
            "        [0.9984],\n",
            "        [0.9971],\n",
            "        [0.9953],\n",
            "        [0.9982],\n",
            "        [0.9981],\n",
            "        [0.9983],\n",
            "        [0.9985],\n",
            "        [0.9967],\n",
            "        [0.9980],\n",
            "        [0.9884],\n",
            "        [0.9984],\n",
            "        [0.9992],\n",
            "        [0.9982],\n",
            "        [0.9977],\n",
            "        [0.9991],\n",
            "        [0.0064],\n",
            "        [0.9339]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9991],\n",
            "        [0.0045],\n",
            "        [0.9988],\n",
            "        [0.0995],\n",
            "        [0.9951],\n",
            "        [0.9949],\n",
            "        [0.4713],\n",
            "        [0.9982],\n",
            "        [0.9991],\n",
            "        [0.9961],\n",
            "        [0.9981],\n",
            "        [0.9986],\n",
            "        [0.9984],\n",
            "        [0.9972],\n",
            "        [0.9986],\n",
            "        [0.9995],\n",
            "        [0.9991],\n",
            "        [0.9983],\n",
            "        [0.9966],\n",
            "        [0.9966],\n",
            "        [0.0034],\n",
            "        [0.9922],\n",
            "        [0.9918],\n",
            "        [0.9995],\n",
            "        [0.9970],\n",
            "        [0.9966],\n",
            "        [0.9981],\n",
            "        [0.9978],\n",
            "        [0.9974],\n",
            "        [0.9973],\n",
            "        [0.9990],\n",
            "        [0.9915]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9971],\n",
            "        [0.9986],\n",
            "        [0.9977],\n",
            "        [0.9983],\n",
            "        [0.9985],\n",
            "        [0.9992],\n",
            "        [0.9969],\n",
            "        [0.9947],\n",
            "        [0.0078],\n",
            "        [0.9992],\n",
            "        [0.9962],\n",
            "        [0.9981],\n",
            "        [0.0024],\n",
            "        [0.9990],\n",
            "        [0.9980],\n",
            "        [0.9958],\n",
            "        [0.9580],\n",
            "        [0.9992],\n",
            "        [0.9986],\n",
            "        [0.9994],\n",
            "        [0.9991],\n",
            "        [0.9958],\n",
            "        [0.9990],\n",
            "        [0.9960],\n",
            "        [0.9945],\n",
            "        [0.9970],\n",
            "        [0.9982],\n",
            "        [0.9976],\n",
            "        [0.9983],\n",
            "        [0.9978],\n",
            "        [0.9972],\n",
            "        [0.9984]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9709],\n",
            "        [0.9983],\n",
            "        [0.9989],\n",
            "        [0.9809],\n",
            "        [0.9895],\n",
            "        [0.9987],\n",
            "        [0.9963],\n",
            "        [0.0019],\n",
            "        [0.9958],\n",
            "        [0.9959],\n",
            "        [0.9956],\n",
            "        [0.9986],\n",
            "        [0.9983],\n",
            "        [0.0441],\n",
            "        [0.9984],\n",
            "        [0.9980],\n",
            "        [0.9972],\n",
            "        [0.9991],\n",
            "        [0.9986],\n",
            "        [0.9967],\n",
            "        [0.9989],\n",
            "        [0.9813],\n",
            "        [0.9986],\n",
            "        [0.9993],\n",
            "        [0.9964],\n",
            "        [0.9988],\n",
            "        [0.9980],\n",
            "        [0.9979],\n",
            "        [0.9993],\n",
            "        [0.9891],\n",
            "        [0.9958],\n",
            "        [0.9982]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9888],\n",
            "        [0.9984],\n",
            "        [0.9967],\n",
            "        [0.9967],\n",
            "        [0.9907],\n",
            "        [0.9983],\n",
            "        [0.9982],\n",
            "        [0.9967],\n",
            "        [0.9978],\n",
            "        [0.9960],\n",
            "        [0.9983],\n",
            "        [0.9986],\n",
            "        [0.9980],\n",
            "        [0.9990],\n",
            "        [0.9967],\n",
            "        [0.9976],\n",
            "        [0.9990],\n",
            "        [0.9967],\n",
            "        [0.9966],\n",
            "        [0.9984],\n",
            "        [0.9978],\n",
            "        [0.9979],\n",
            "        [0.9992],\n",
            "        [0.9992],\n",
            "        [0.9996],\n",
            "        [0.9938],\n",
            "        [0.9995],\n",
            "        [0.9987],\n",
            "        [0.9988],\n",
            "        [0.9849],\n",
            "        [0.9989],\n",
            "        [0.9620]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9988],\n",
            "        [0.9983],\n",
            "        [0.9995],\n",
            "        [0.9972],\n",
            "        [0.9985],\n",
            "        [0.9984],\n",
            "        [0.9979],\n",
            "        [0.0018],\n",
            "        [0.9812],\n",
            "        [0.9987],\n",
            "        [0.9974],\n",
            "        [0.9982],\n",
            "        [0.9995],\n",
            "        [0.9993],\n",
            "        [0.9992],\n",
            "        [0.9993],\n",
            "        [0.2810],\n",
            "        [0.9982],\n",
            "        [0.9986],\n",
            "        [0.9994],\n",
            "        [0.9955],\n",
            "        [0.9983],\n",
            "        [0.9993],\n",
            "        [0.9908],\n",
            "        [0.9986],\n",
            "        [0.9991],\n",
            "        [0.9981],\n",
            "        [0.9959],\n",
            "        [0.9927],\n",
            "        [0.9965],\n",
            "        [0.9986],\n",
            "        [0.9991]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9983],\n",
            "        [0.9986],\n",
            "        [0.0145],\n",
            "        [0.9989],\n",
            "        [0.9991],\n",
            "        [0.9994],\n",
            "        [0.9982],\n",
            "        [0.0274],\n",
            "        [0.9995],\n",
            "        [0.9956],\n",
            "        [0.9981],\n",
            "        [0.9972],\n",
            "        [0.9984],\n",
            "        [0.9984],\n",
            "        [0.9990],\n",
            "        [0.9945],\n",
            "        [0.9990],\n",
            "        [0.0024],\n",
            "        [0.9981],\n",
            "        [0.9993],\n",
            "        [0.9988],\n",
            "        [0.0099],\n",
            "        [0.9984],\n",
            "        [0.9981],\n",
            "        [0.9993],\n",
            "        [0.9990],\n",
            "        [0.9988],\n",
            "        [0.9986],\n",
            "        [0.9974],\n",
            "        [0.9987],\n",
            "        [0.9930],\n",
            "        [0.9982]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.0020],\n",
            "        [0.9969],\n",
            "        [0.9988],\n",
            "        [0.9990],\n",
            "        [0.9995],\n",
            "        [0.9988],\n",
            "        [0.9956],\n",
            "        [0.9894],\n",
            "        [0.9978],\n",
            "        [0.9971],\n",
            "        [0.9986],\n",
            "        [0.9962],\n",
            "        [0.9988],\n",
            "        [0.9987],\n",
            "        [0.9993],\n",
            "        [0.9990],\n",
            "        [0.0026],\n",
            "        [0.9986],\n",
            "        [0.9979],\n",
            "        [0.9990],\n",
            "        [0.9964],\n",
            "        [0.9990],\n",
            "        [0.9953],\n",
            "        [0.9994],\n",
            "        [0.9985],\n",
            "        [0.9980],\n",
            "        [0.9986],\n",
            "        [0.9958],\n",
            "        [0.9985],\n",
            "        [0.9994],\n",
            "        [0.9991],\n",
            "        [0.9954]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9946],\n",
            "        [0.9971],\n",
            "        [0.9983],\n",
            "        [0.9981],\n",
            "        [0.9970],\n",
            "        [0.9982],\n",
            "        [0.9950],\n",
            "        [0.9994],\n",
            "        [0.9986],\n",
            "        [0.9990],\n",
            "        [0.9981],\n",
            "        [0.9993],\n",
            "        [0.9957],\n",
            "        [0.9988],\n",
            "        [0.9989],\n",
            "        [0.9983],\n",
            "        [0.9991],\n",
            "        [0.9984],\n",
            "        [0.9979],\n",
            "        [0.9955],\n",
            "        [0.9986],\n",
            "        [0.9992],\n",
            "        [0.9972],\n",
            "        [0.9979],\n",
            "        [0.9945],\n",
            "        [0.9939],\n",
            "        [0.9980],\n",
            "        [0.9961],\n",
            "        [0.9965],\n",
            "        [0.0429],\n",
            "        [0.9988],\n",
            "        [0.9985]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9993],\n",
            "        [0.9974],\n",
            "        [0.9987],\n",
            "        [0.9985],\n",
            "        [0.9985],\n",
            "        [0.9986],\n",
            "        [0.9952],\n",
            "        [0.0080],\n",
            "        [0.9991],\n",
            "        [0.9990],\n",
            "        [0.9980],\n",
            "        [0.9980],\n",
            "        [0.9942],\n",
            "        [0.9970],\n",
            "        [0.9985],\n",
            "        [0.9984],\n",
            "        [0.9982],\n",
            "        [0.9980],\n",
            "        [0.9986],\n",
            "        [0.9972],\n",
            "        [0.9972],\n",
            "        [0.9986],\n",
            "        [0.9995],\n",
            "        [0.9994],\n",
            "        [0.9974],\n",
            "        [0.9980],\n",
            "        [0.9979],\n",
            "        [0.9984],\n",
            "        [0.9938],\n",
            "        [0.9983],\n",
            "        [0.9986],\n",
            "        [0.9977]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9915],\n",
            "        [0.0043],\n",
            "        [0.0053],\n",
            "        [0.9989],\n",
            "        [0.9990],\n",
            "        [0.9982],\n",
            "        [0.9973],\n",
            "        [0.9987],\n",
            "        [0.9974],\n",
            "        [0.9963],\n",
            "        [0.9975],\n",
            "        [0.9969],\n",
            "        [0.9993],\n",
            "        [0.9985],\n",
            "        [0.9966],\n",
            "        [0.9969],\n",
            "        [0.9978],\n",
            "        [0.9979],\n",
            "        [0.9992],\n",
            "        [0.8230],\n",
            "        [0.9990],\n",
            "        [0.9966],\n",
            "        [0.9980],\n",
            "        [0.0865],\n",
            "        [0.0041],\n",
            "        [0.9990],\n",
            "        [0.9975],\n",
            "        [0.9987],\n",
            "        [0.9984],\n",
            "        [0.9990],\n",
            "        [0.9933],\n",
            "        [0.9992]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9882],\n",
            "        [0.9970],\n",
            "        [0.9986],\n",
            "        [0.9988],\n",
            "        [0.9985],\n",
            "        [0.9989],\n",
            "        [0.9982],\n",
            "        [0.9993],\n",
            "        [0.9968],\n",
            "        [0.9994],\n",
            "        [0.9985],\n",
            "        [0.0055],\n",
            "        [0.9992],\n",
            "        [0.9982],\n",
            "        [0.9981],\n",
            "        [0.9912],\n",
            "        [0.9988],\n",
            "        [0.9992],\n",
            "        [0.9969],\n",
            "        [0.9981],\n",
            "        [0.9416],\n",
            "        [0.9993],\n",
            "        [0.9987],\n",
            "        [0.9986],\n",
            "        [0.9984],\n",
            "        [0.9928],\n",
            "        [0.9989],\n",
            "        [0.9990],\n",
            "        [0.9990],\n",
            "        [0.9976],\n",
            "        [0.9994],\n",
            "        [0.9989]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9984],\n",
            "        [0.9991],\n",
            "        [0.9987],\n",
            "        [0.9980],\n",
            "        [0.9827],\n",
            "        [0.5870],\n",
            "        [0.9985],\n",
            "        [0.0025],\n",
            "        [0.0112],\n",
            "        [0.9984],\n",
            "        [0.9967],\n",
            "        [0.9979],\n",
            "        [0.9922],\n",
            "        [0.9901],\n",
            "        [0.9994],\n",
            "        [0.9961],\n",
            "        [0.0047],\n",
            "        [0.9990],\n",
            "        [0.9987],\n",
            "        [0.9762],\n",
            "        [0.9968],\n",
            "        [0.0017],\n",
            "        [0.9990],\n",
            "        [0.9989],\n",
            "        [0.9981],\n",
            "        [0.9990],\n",
            "        [0.9964],\n",
            "        [0.0021],\n",
            "        [0.9972],\n",
            "        [0.9993],\n",
            "        [0.9975],\n",
            "        [0.9989]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9994],\n",
            "        [0.9966],\n",
            "        [0.9989],\n",
            "        [0.9983],\n",
            "        [0.9990],\n",
            "        [0.9989],\n",
            "        [0.9985],\n",
            "        [0.9931],\n",
            "        [0.9990],\n",
            "        [0.9975],\n",
            "        [0.0306],\n",
            "        [0.0021],\n",
            "        [0.9989],\n",
            "        [0.9990],\n",
            "        [0.9978],\n",
            "        [0.9974],\n",
            "        [0.9839],\n",
            "        [0.9949],\n",
            "        [0.9984],\n",
            "        [0.9960],\n",
            "        [0.9977],\n",
            "        [0.9976],\n",
            "        [0.0028],\n",
            "        [0.9995],\n",
            "        [0.9983],\n",
            "        [0.9989],\n",
            "        [0.9971],\n",
            "        [0.9990],\n",
            "        [0.9965],\n",
            "        [0.9987],\n",
            "        [0.9986],\n",
            "        [0.9990]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9994],\n",
            "        [0.9983],\n",
            "        [0.9991],\n",
            "        [0.9950],\n",
            "        [0.9976],\n",
            "        [0.9943],\n",
            "        [0.9987],\n",
            "        [0.9975],\n",
            "        [0.9993],\n",
            "        [0.9984],\n",
            "        [0.9985],\n",
            "        [0.9989],\n",
            "        [0.9990],\n",
            "        [0.9988],\n",
            "        [0.9967],\n",
            "        [0.9987],\n",
            "        [0.9969],\n",
            "        [0.9991],\n",
            "        [0.9972],\n",
            "        [0.9992],\n",
            "        [0.9963],\n",
            "        [0.9982],\n",
            "        [0.9969],\n",
            "        [0.9987],\n",
            "        [0.9978],\n",
            "        [0.9969],\n",
            "        [0.9980],\n",
            "        [0.2208],\n",
            "        [0.9974],\n",
            "        [0.9990],\n",
            "        [0.0034],\n",
            "        [0.9990]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9951],\n",
            "        [0.9970],\n",
            "        [0.9983],\n",
            "        [0.9988],\n",
            "        [0.9987],\n",
            "        [0.9958],\n",
            "        [0.9981],\n",
            "        [0.9980],\n",
            "        [0.9976],\n",
            "        [0.9991],\n",
            "        [0.9980],\n",
            "        [0.9978],\n",
            "        [0.9979],\n",
            "        [0.0582],\n",
            "        [0.0057],\n",
            "        [0.9991],\n",
            "        [0.7919],\n",
            "        [0.9992],\n",
            "        [0.9982],\n",
            "        [0.9986],\n",
            "        [0.9988],\n",
            "        [0.9913],\n",
            "        [0.9973],\n",
            "        [0.9983],\n",
            "        [0.0063],\n",
            "        [0.9984],\n",
            "        [0.9978],\n",
            "        [0.9967],\n",
            "        [0.9969],\n",
            "        [0.9992],\n",
            "        [0.9983],\n",
            "        [0.9977]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9965],\n",
            "        [0.9990],\n",
            "        [0.0035],\n",
            "        [0.9995],\n",
            "        [0.9986],\n",
            "        [0.9993],\n",
            "        [0.9976],\n",
            "        [0.9988],\n",
            "        [0.9994],\n",
            "        [0.9939],\n",
            "        [0.9956],\n",
            "        [0.9987],\n",
            "        [0.9968],\n",
            "        [0.9982],\n",
            "        [0.9820],\n",
            "        [0.9994],\n",
            "        [0.9982],\n",
            "        [0.9984],\n",
            "        [0.9439],\n",
            "        [0.9981],\n",
            "        [0.9971],\n",
            "        [0.9991],\n",
            "        [0.9983],\n",
            "        [0.9989],\n",
            "        [0.9940],\n",
            "        [0.9989],\n",
            "        [0.9971],\n",
            "        [0.9979],\n",
            "        [0.9996],\n",
            "        [0.9940],\n",
            "        [0.9971],\n",
            "        [0.9995]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9919],\n",
            "        [0.9984],\n",
            "        [0.9986],\n",
            "        [0.9963],\n",
            "        [0.9980],\n",
            "        [0.9993],\n",
            "        [0.9986],\n",
            "        [0.9968],\n",
            "        [0.9965],\n",
            "        [0.9986],\n",
            "        [0.9987],\n",
            "        [0.9974],\n",
            "        [0.9994],\n",
            "        [0.9989],\n",
            "        [0.9987],\n",
            "        [0.9930],\n",
            "        [0.0259],\n",
            "        [0.9988],\n",
            "        [0.9990],\n",
            "        [0.9993],\n",
            "        [0.3570],\n",
            "        [0.9953],\n",
            "        [0.9994],\n",
            "        [0.9962],\n",
            "        [0.9983],\n",
            "        [0.9975],\n",
            "        [0.9994],\n",
            "        [0.9992],\n",
            "        [0.9980],\n",
            "        [0.9988],\n",
            "        [0.9953],\n",
            "        [0.9969]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9979],\n",
            "        [0.9964],\n",
            "        [0.9959],\n",
            "        [0.9991],\n",
            "        [0.9977],\n",
            "        [0.9991],\n",
            "        [0.9989],\n",
            "        [0.9990],\n",
            "        [0.9978],\n",
            "        [0.9981],\n",
            "        [0.9929],\n",
            "        [0.9984],\n",
            "        [0.9897],\n",
            "        [0.9972],\n",
            "        [0.9961],\n",
            "        [0.9965],\n",
            "        [0.9962],\n",
            "        [0.9977],\n",
            "        [0.9990],\n",
            "        [0.9986],\n",
            "        [0.9971],\n",
            "        [0.9978],\n",
            "        [0.9987],\n",
            "        [0.0139],\n",
            "        [0.0098],\n",
            "        [0.9973],\n",
            "        [0.9985],\n",
            "        [0.9989],\n",
            "        [0.9979],\n",
            "        [0.9992],\n",
            "        [0.9984],\n",
            "        [0.9976]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9991],\n",
            "        [0.9983],\n",
            "        [0.9984],\n",
            "        [0.9987],\n",
            "        [0.9973],\n",
            "        [0.0030],\n",
            "        [0.9988],\n",
            "        [0.9988],\n",
            "        [0.9944],\n",
            "        [0.9968],\n",
            "        [0.9995],\n",
            "        [0.9986],\n",
            "        [0.9988],\n",
            "        [0.9989],\n",
            "        [0.9951],\n",
            "        [0.9978],\n",
            "        [0.9927],\n",
            "        [0.9994],\n",
            "        [0.9990],\n",
            "        [0.9985],\n",
            "        [0.9987],\n",
            "        [0.9975],\n",
            "        [0.0053],\n",
            "        [0.9976],\n",
            "        [0.9977],\n",
            "        [0.9989],\n",
            "        [0.9979],\n",
            "        [0.9986],\n",
            "        [0.9940],\n",
            "        [0.9951],\n",
            "        [0.9977],\n",
            "        [0.9979]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9976],\n",
            "        [0.9978],\n",
            "        [0.9984],\n",
            "        [0.9922],\n",
            "        [0.9979],\n",
            "        [0.9991],\n",
            "        [0.0034],\n",
            "        [0.9970],\n",
            "        [0.9959],\n",
            "        [0.9985],\n",
            "        [0.9962],\n",
            "        [0.9952],\n",
            "        [0.9986],\n",
            "        [0.9978],\n",
            "        [0.0032],\n",
            "        [0.9958],\n",
            "        [0.9985],\n",
            "        [0.9987],\n",
            "        [0.9989],\n",
            "        [0.9966],\n",
            "        [0.9942],\n",
            "        [0.9989],\n",
            "        [0.9849],\n",
            "        [0.9983],\n",
            "        [0.9983],\n",
            "        [0.9974],\n",
            "        [0.9991],\n",
            "        [0.9956],\n",
            "        [0.9988],\n",
            "        [0.9948],\n",
            "        [0.9991],\n",
            "        [0.9949]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9990],\n",
            "        [0.9982],\n",
            "        [0.9985],\n",
            "        [0.9983],\n",
            "        [0.9968],\n",
            "        [0.9988],\n",
            "        [0.9992],\n",
            "        [0.9988],\n",
            "        [0.0147],\n",
            "        [0.9531],\n",
            "        [0.9992],\n",
            "        [0.0064],\n",
            "        [0.9957],\n",
            "        [0.9977],\n",
            "        [0.9995],\n",
            "        [0.9676],\n",
            "        [0.9986],\n",
            "        [0.9562],\n",
            "        [0.9991],\n",
            "        [0.9992],\n",
            "        [0.9379],\n",
            "        [0.9990],\n",
            "        [0.9984],\n",
            "        [0.9961],\n",
            "        [0.9963],\n",
            "        [0.9986],\n",
            "        [0.9966],\n",
            "        [0.9953],\n",
            "        [0.0024],\n",
            "        [0.0513],\n",
            "        [0.9987],\n",
            "        [0.0038]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.]], device='cuda:0')\n",
            "outputs : tensor([[0.9897],\n",
            "        [0.9941],\n",
            "        [0.9994],\n",
            "        [0.9984],\n",
            "        [0.9599],\n",
            "        [0.9661],\n",
            "        [0.9992],\n",
            "        [0.9989],\n",
            "        [0.9984],\n",
            "        [0.9911],\n",
            "        [0.9985],\n",
            "        [0.9988],\n",
            "        [0.9993],\n",
            "        [0.9982],\n",
            "        [0.9966],\n",
            "        [0.9954],\n",
            "        [0.9983],\n",
            "        [0.9987],\n",
            "        [0.9988],\n",
            "        [0.9991],\n",
            "        [0.9986],\n",
            "        [0.9956],\n",
            "        [0.9993],\n",
            "        [0.9991],\n",
            "        [0.9985],\n",
            "        [0.9990],\n",
            "        [0.9972],\n",
            "        [0.9988],\n",
            "        [0.9981],\n",
            "        [0.9992],\n",
            "        [0.9991],\n",
            "        [0.9966]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9989],\n",
            "        [0.9970],\n",
            "        [0.9953],\n",
            "        [0.9957],\n",
            "        [0.9991],\n",
            "        [0.9993],\n",
            "        [0.9973],\n",
            "        [0.9996],\n",
            "        [0.9947],\n",
            "        [0.0020],\n",
            "        [0.9982],\n",
            "        [0.9983],\n",
            "        [0.9983],\n",
            "        [0.9944],\n",
            "        [0.9992],\n",
            "        [0.9948],\n",
            "        [0.9980],\n",
            "        [0.9979],\n",
            "        [0.9977],\n",
            "        [0.9988],\n",
            "        [0.9969],\n",
            "        [0.9991],\n",
            "        [0.9988],\n",
            "        [0.9971],\n",
            "        [0.9992],\n",
            "        [0.9988],\n",
            "        [0.9963],\n",
            "        [0.9981],\n",
            "        [0.9985],\n",
            "        [0.0074],\n",
            "        [0.9993],\n",
            "        [0.9979]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9995],\n",
            "        [0.9984],\n",
            "        [0.9962],\n",
            "        [0.9837],\n",
            "        [0.8713],\n",
            "        [0.9990],\n",
            "        [0.9991],\n",
            "        [0.9957],\n",
            "        [0.9986],\n",
            "        [0.0015],\n",
            "        [0.9991],\n",
            "        [0.9973],\n",
            "        [0.9982],\n",
            "        [0.9985],\n",
            "        [0.9995],\n",
            "        [0.9725],\n",
            "        [0.9994],\n",
            "        [0.9970],\n",
            "        [0.9951],\n",
            "        [0.9981],\n",
            "        [0.9970],\n",
            "        [0.0035],\n",
            "        [0.9928],\n",
            "        [0.9987],\n",
            "        [0.9988],\n",
            "        [0.9993],\n",
            "        [0.9976],\n",
            "        [0.9986],\n",
            "        [0.9986],\n",
            "        [0.9985],\n",
            "        [0.9986],\n",
            "        [0.9979]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "Batch   280 of   288. Elapsed: 0:01:44.\n",
            "outputs : tensor([[0.9983],\n",
            "        [0.9993],\n",
            "        [0.9985],\n",
            "        [0.9967],\n",
            "        [0.9974],\n",
            "        [0.9959],\n",
            "        [0.9982],\n",
            "        [0.9960],\n",
            "        [0.0081],\n",
            "        [0.9972],\n",
            "        [0.9944],\n",
            "        [0.9958],\n",
            "        [0.9958],\n",
            "        [0.9985],\n",
            "        [0.9983],\n",
            "        [0.9974],\n",
            "        [0.7302],\n",
            "        [0.9949],\n",
            "        [0.9986],\n",
            "        [0.9958],\n",
            "        [0.0026],\n",
            "        [0.9990],\n",
            "        [0.9993],\n",
            "        [0.9988],\n",
            "        [0.9985],\n",
            "        [0.9988],\n",
            "        [0.9979],\n",
            "        [0.9972],\n",
            "        [0.9956],\n",
            "        [0.9991],\n",
            "        [0.9994],\n",
            "        [0.9993]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9983],\n",
            "        [0.9883],\n",
            "        [0.9962],\n",
            "        [0.9987],\n",
            "        [0.9954],\n",
            "        [0.9878],\n",
            "        [0.9945],\n",
            "        [0.9988],\n",
            "        [0.0035],\n",
            "        [0.9995],\n",
            "        [0.9990],\n",
            "        [0.0751],\n",
            "        [0.9995],\n",
            "        [0.9981],\n",
            "        [0.9989],\n",
            "        [0.9985],\n",
            "        [0.9957],\n",
            "        [0.9990],\n",
            "        [0.9974],\n",
            "        [0.9967],\n",
            "        [0.9986],\n",
            "        [0.9978],\n",
            "        [0.9987],\n",
            "        [0.9963],\n",
            "        [0.9975],\n",
            "        [0.0026],\n",
            "        [0.9987],\n",
            "        [0.9990],\n",
            "        [0.0050],\n",
            "        [0.9979],\n",
            "        [0.9981],\n",
            "        [0.9940]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9979],\n",
            "        [0.9940],\n",
            "        [0.5437],\n",
            "        [0.9994],\n",
            "        [0.9984],\n",
            "        [0.9990],\n",
            "        [0.9995],\n",
            "        [0.9951],\n",
            "        [0.9982],\n",
            "        [0.9988],\n",
            "        [0.9988],\n",
            "        [0.9902],\n",
            "        [0.9977],\n",
            "        [0.9962],\n",
            "        [0.0263],\n",
            "        [0.9977],\n",
            "        [0.9958],\n",
            "        [0.9981],\n",
            "        [0.9946],\n",
            "        [0.9975],\n",
            "        [0.9950],\n",
            "        [0.9982],\n",
            "        [0.9975],\n",
            "        [0.9994],\n",
            "        [0.9991],\n",
            "        [0.9975],\n",
            "        [0.9989],\n",
            "        [0.9986],\n",
            "        [0.9984],\n",
            "        [0.9991],\n",
            "        [0.9966],\n",
            "        [0.9984]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9985],\n",
            "        [0.9979],\n",
            "        [0.9985],\n",
            "        [0.9980],\n",
            "        [0.9994],\n",
            "        [0.9971],\n",
            "        [0.9948],\n",
            "        [0.9992],\n",
            "        [0.9984],\n",
            "        [0.9979],\n",
            "        [0.9977],\n",
            "        [0.9994],\n",
            "        [0.9991],\n",
            "        [0.9992],\n",
            "        [0.9954],\n",
            "        [0.9995],\n",
            "        [0.9986],\n",
            "        [0.9963],\n",
            "        [0.9986],\n",
            "        [0.0173],\n",
            "        [0.9993],\n",
            "        [0.9986],\n",
            "        [0.9987],\n",
            "        [0.9981],\n",
            "        [0.9989],\n",
            "        [0.9957],\n",
            "        [0.9842],\n",
            "        [0.0017],\n",
            "        [0.9989],\n",
            "        [0.9723],\n",
            "        [0.9989],\n",
            "        [0.9979]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9988],\n",
            "        [0.9977],\n",
            "        [0.0123],\n",
            "        [0.9987],\n",
            "        [0.9985],\n",
            "        [0.9985],\n",
            "        [0.9981],\n",
            "        [0.9991],\n",
            "        [0.9968],\n",
            "        [0.9816],\n",
            "        [0.9979],\n",
            "        [0.9989],\n",
            "        [0.9991],\n",
            "        [0.9994],\n",
            "        [0.9986],\n",
            "        [0.9983],\n",
            "        [0.9969],\n",
            "        [0.0036],\n",
            "        [0.9992],\n",
            "        [0.9980],\n",
            "        [0.9991],\n",
            "        [0.9983],\n",
            "        [0.9992],\n",
            "        [0.0190],\n",
            "        [0.9979],\n",
            "        [0.9975],\n",
            "        [0.9978],\n",
            "        [0.9905],\n",
            "        [0.9994],\n",
            "        [0.9951],\n",
            "        [0.1818],\n",
            "        [0.9991]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9949],\n",
            "        [0.9995],\n",
            "        [0.9993],\n",
            "        [0.9989],\n",
            "        [0.9993],\n",
            "        [0.9992],\n",
            "        [0.9981],\n",
            "        [0.9987],\n",
            "        [0.9929],\n",
            "        [0.9965],\n",
            "        [0.9992],\n",
            "        [0.0034],\n",
            "        [0.9988],\n",
            "        [0.9990],\n",
            "        [0.9984],\n",
            "        [0.9993],\n",
            "        [0.9975],\n",
            "        [0.9995],\n",
            "        [0.9992],\n",
            "        [0.9979],\n",
            "        [0.9983],\n",
            "        [0.9992],\n",
            "        [0.9988],\n",
            "        [0.9986],\n",
            "        [0.9975],\n",
            "        [0.9990],\n",
            "        [0.0033],\n",
            "        [0.9915],\n",
            "        [0.9986],\n",
            "        [0.9992],\n",
            "        [0.9943],\n",
            "        [0.9993]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9990],\n",
            "        [0.9986],\n",
            "        [0.9978],\n",
            "        [0.9990],\n",
            "        [0.9987],\n",
            "        [0.9979],\n",
            "        [0.9986],\n",
            "        [0.9970],\n",
            "        [0.9967],\n",
            "        [0.9931],\n",
            "        [0.9982],\n",
            "        [0.9987],\n",
            "        [0.9994],\n",
            "        [0.9986],\n",
            "        [0.0042],\n",
            "        [0.9903],\n",
            "        [0.9990],\n",
            "        [0.9974],\n",
            "        [0.9981],\n",
            "        [0.9991],\n",
            "        [0.9985],\n",
            "        [0.9969],\n",
            "        [0.9970],\n",
            "        [0.0050],\n",
            "        [0.9980],\n",
            "        [0.9965],\n",
            "        [0.9992],\n",
            "        [0.9980],\n",
            "        [0.9977],\n",
            "        [0.9967],\n",
            "        [0.9994],\n",
            "        [0.9995]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "outputs : tensor([[0.9851],\n",
            "        [0.9886],\n",
            "        [0.9991],\n",
            "        [0.0029],\n",
            "        [0.9985],\n",
            "        [0.9987],\n",
            "        [0.9959],\n",
            "        [0.9977],\n",
            "        [0.9990],\n",
            "        [0.0058],\n",
            "        [0.9969],\n",
            "        [0.9987]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "b_labels : tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0')\n",
            "\n",
            "Average training loss: 0.04\n",
            "Training epoch took: 0:01:46\n",
            "\n",
            "Running Validation...\n",
            "Accuracy: 0.08\n",
            "Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HEWjeywybKL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d82b0783-16ef-4dea-b216-c4012dc40e88"
      },
      "source": [
        "# visualize training loss over all batches\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVQTc7Yd5wR8"
      },
      "source": [
        "## Performance on Test set\n",
        "\n",
        "- `sklearn` 라이브러리의 `classification_report` 함수 이용하여 **accuracy, precision, recall, f1 score** 평가 지표를 이용하여 test dataset 에 대해 성능 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2WTICpmy_oA",
        "outputId": "781f2a83-5375-4f57-9363-f47f2d288b0d"
      },
      "source": [
        "type(test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eafzUr_9zB7K",
        "outputId": "37c6e76a-9b56-4ca5-d48a-a09d3d332146"
      },
      "source": [
        "type(test_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68rTtPWjzbMp",
        "outputId": "96bee8d9-4dd0-479c-a139-4eb12b921558"
      },
      "source": [
        "print(test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['  baby... nothing can ever break us apart... i love you so much and i want to be with you for ever. i really love you... for ever... and ever. *you are the only exception*. (l) <3 <3 <3 <3   ily2 u2665'\n",
            " '  does your stomach make noise when your terribly hungry?smh mines do all the time ughh:(   yeah sometimes or i just get a really sore head'\n",
            " '  do you have your own bank account?:   mes  they can be fun' ...\n",
            " \"  the stupids is about a family mr and mrs stupid and their children. they're rather quite stupid. it's a comedy and is rather hilarious...they're just stupid! haha. it's awesome. they do something good  it's a nice story. only available on region 1 dvd :-(   ohhhh  well thats a faillll because i don't have a multiregional player :( i might watch it online or something  thanks :d\"\n",
            " '  u mad?   nope im good'\n",
            " '  who asks people if they know me why do i see it all the time who is it that cares   you have a fan d00d. can you sign my bewbs?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bfw6WvDzdkZ",
        "outputId": "51fa4838-924b-4473-f571-6b51fa149fd1"
      },
      "source": [
        "len(test_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2555"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIg14zYC50F1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df3f096c-80b7-48b4-a18b-e46d2b0ca668"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_data:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = tf.keras.preprocessing.sequence.pad_sequences(input_ids, maxlen=MAXLEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence\n",
        "for sent in input_ids:\n",
        "    # Create the attention mask.\n",
        "    #  - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #  - If a token ID is not 0 ( > 0), then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)\n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(test_label)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PK69aZG6kWt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f11559a8-a5d9-432a-8a34-adc664dd195d"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "preds = []\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, b_input_mask, token_type_ids=None)\n",
        "\n",
        "  preds += list(outputs.cpu().numpy().flatten())\n",
        "\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  true_labels.extend(label_ids.flatten())\n",
        "\n",
        "\n",
        "print('DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 2,555 test sentences...\n",
            "DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzAXUuqDQh6u",
        "outputId": "9fb74c48-d9a4-4dca-97d1-a03f6fdfad1b"
      },
      "source": [
        "pre = [int(x >= 0.5) for x in preds]\n",
        "print(pre)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5uWsW5Ty0gF",
        "outputId": "914a1a8e-e937-4aa7-8968-9201b37e19fc"
      },
      "source": [
        "len(pre)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2555"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vo86hevy8XE",
        "outputId": "98f16669-9f4c-4580-d375-ce97d0fc47ac"
      },
      "source": [
        "len(true_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2555"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3o8SfUnV--K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a79d1f26-c7ec-4b17-9d9e-a12391ca8aec"
      },
      "source": [
        "# accuracy, precision, recall, f1 score 성능 확인\n",
        "from sklearn.metrics import classification_report\n",
        "    \n",
        "target_names = ['negative', 'positive']\n",
        "\n",
        "print(classification_report(true_labels, pre, digits=4, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative     0.5693    0.5455    0.5571       143\n",
            "    positive     0.9731    0.9755    0.9743      2412\n",
            "\n",
            "    accuracy                         0.9515      2555\n",
            "   macro avg     0.7712    0.7605    0.7657      2555\n",
            "weighted avg     0.9505    0.9515    0.9510      2555\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qH_FBEWslsB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}