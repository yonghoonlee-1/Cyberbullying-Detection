{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Formspring__CNN-BiLSTM",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNd5GhRV3SNgCT9vqR8864N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yonghoonlee-1/Cyberbullying-Detection/blob/main/Formspring__CNN_BiLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cj7tffTOTK8O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdd47491-789b-4c69-f531-14df8f078a20"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "!rm -rf /content/gdrive\n",
        "!ln -s \"/gdrive/My Drive\" /content/gdrive\n",
        "%cd /content/gdrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0QwqxZnTFRO"
      },
      "source": [
        "import keras\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Embedding, LSTM\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQNAs-AbTNp1"
      },
      "source": [
        "formspring=pd.read_csv(\"/content/gdrive/formspring_data.csv\", encoding='latin1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVEeMmVYTTlO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "569385ef-b5b5-435b-8716-7d3ccab61024"
      },
      "source": [
        "formspring.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Q: what&amp;#039;s your favorite song? :D&lt;br&gt;A: I ...</td>\n",
              "      <td>non-bully</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Q: &lt;3&lt;br&gt;A: &lt;/3 ? haha jk! &lt;33</td>\n",
              "      <td>non-bully</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Q: &amp;quot;hey angel  you duh sexy&amp;quot;&lt;br&gt;A: R...</td>\n",
              "      <td>non-bully</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Q: (:&lt;br&gt;A: ;(</td>\n",
              "      <td>non-bully</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Q: ******************MEOWWW*******************...</td>\n",
              "      <td>non-bully</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Q: any makeup tips? i suck at doing my makeup ...</td>\n",
              "      <td>non-bully</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Q: Apriiiiiiiiiiiill!!! I miss uuuu! It&amp;#039;s...</td>\n",
              "      <td>non-bully</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Q: Are you a morning or night person?&lt;br&gt;A: Ni...</td>\n",
              "      <td>non-bully</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Q: are you a trusting person?&lt;br&gt;A: alreadi an...</td>\n",
              "      <td>non-bully</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Q: are you a trusting person?&lt;br&gt;A: Yes veryy ...</td>\n",
              "      <td>non-bully</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  sentiment\n",
              "0  Q: what&#039;s your favorite song? :D<br>A: I ...  non-bully\n",
              "1                     Q: <3<br>A: </3 ? haha jk! <33  non-bully\n",
              "2  Q: &quot;hey angel  you duh sexy&quot;<br>A: R...  non-bully\n",
              "3                                     Q: (:<br>A: ;(  non-bully\n",
              "4  Q: ******************MEOWWW*******************...  non-bully\n",
              "5  Q: any makeup tips? i suck at doing my makeup ...  non-bully\n",
              "6  Q: Apriiiiiiiiiiiill!!! I miss uuuu! It&#039;s...  non-bully\n",
              "7  Q: Are you a morning or night person?<br>A: Ni...  non-bully\n",
              "8  Q: are you a trusting person?<br>A: alreadi an...  non-bully\n",
              "9  Q: are you a trusting person?<br>A: Yes veryy ...  non-bully"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBPSTpSPTVXJ"
      },
      "source": [
        "data = formspring[['sentence','sentiment']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf2HNdhuTW5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e1bb923-8c1c-4ffe-f0cf-79de9a8798da"
      },
      "source": [
        "import string\n",
        "data['sentence'] = data['sentence'].apply(lambda x: x.replace('Q:',' ').replace('A:',' ').replace('<br>',' '))\n",
        "data['sentence'] = data['sentence'].apply(lambda x: x.lower())\n",
        "data['sentence'] = data['sentence'].apply((lambda x: re.sub(r\"(https?|http)://[-a-zA-Z0-9+&@#/%?=~_|!:,.;]*[-a-zA-Z0-9+&@#/%=~_|]\", \"\", x)))\n",
        "data['sentence'] = data['sentence'].apply((lambda x: re.sub(r\"&#039;\", \"\\'\", x)))\n",
        "data['sentence'] = data['sentence'].apply((lambda x: re.sub(r\"&quot;\", \"\", x)))\n",
        "data['sentence'] = data['sentence'].apply((lambda x: re.sub(r\"&amp;\", \"\", x)))\n",
        "data['sentence'] = data['sentence'].apply(lambda x: \"\".join(l for l in x if l not in string.punctuation))\n",
        "print(data[ data['sentiment'] == 'non-bully'].size)\n",
        "print(data[ data['sentiment'] == 'bully'].size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23994\n",
            "1552\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIEsoWP0Uthn"
      },
      "source": [
        "def text_to_wordlist(text, remove_stopwords=True):    \n",
        "\n",
        "    text = text.lower().split()\n",
        "    \n",
        "    if remove_stopwords:\n",
        "        text = [wordnet_lemmatizer.lemmatize(w) for w in text]\n",
        "        text = [w for w in text if w != \"nan\" ]\n",
        "    \n",
        "    text = \" \".join(text)\n",
        "\n",
        "\n",
        "    return(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3HCHOs3UvOl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bc77e99-f8d9-4632-ffa9-121aba84df59"
      },
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('wordnet')\n",
        "wordnet_lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvXRs5oxUx5I"
      },
      "source": [
        "data['sentence'] = data.apply(lambda row: text_to_wordlist(row.sentence).split(), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxoIrxL1TYjU"
      },
      "source": [
        "tokenizer = Tokenizer(split=' ')\n",
        "tokenizer.fit_on_texts(data['sentence'].values)\n",
        "X = tokenizer.texts_to_sequences(data['sentence'].values)\n",
        "X = pad_sequences(X, maxlen=62)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sa-shz7UOFh"
      },
      "source": [
        "Y = pd.get_dummies(data['sentiment']).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcpcjwBASJRj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a60206d-f367-4e11-8be7-1473ae5cfa02"
      },
      "source": [
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12773, 62)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdNCYIXrb30M"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "skf = KFold(n_splits=5, shuffle=True)\n",
        "accuracy = []\n",
        "precision = []\n",
        "recall = []\n",
        "f1_score = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2rF3pYyTaVD"
      },
      "source": [
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "glove_file = open('/content/gdrive/glove.twitter.27B.50d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary [word] = vector_dimensions\n",
        "glove_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-Na1Z5vZsCJ"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "embedding_matrix = zeros((vocab_size, 50))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9pL6TSeawvi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2a3a887-4494-4ed2-e42f-6424e66d86bf"
      },
      "source": [
        "from keras.layers import Bidirectional, Flatten\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D \n",
        "from sklearn import metrics\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "X, Y = shuffle(X, Y, random_state=42)\n",
        "\n",
        "\n",
        "embed_dim = 50\n",
        "lstm_out = 50\n",
        "for train, validation in skf.split(X, Y):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(len(tokenizer.word_index) + 1, embed_dim, weights=[embedding_matrix], input_length = X.shape[1]))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv1D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Bidirectional(LSTM(lstm_out, return_sequences=True)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(2,activation='softmax'))\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "    model.fit(X[train], Y[train], epochs=10, batch_size=128)\n",
        "    k_accuracy = '%.4f' % (model.evaluate(X[validation], Y[validation])[1])\n",
        "    predict_test = (model.predict(X[validation]) >= 0.5) \n",
        "    k_precision = metrics.precision_score(Y[validation], predict_test, average=None)\n",
        "    k_recall = metrics.recall_score(Y[validation], predict_test, average=None)\n",
        "    k_f1_score = metrics.f1_score(Y[validation], predict_test, average=None)\n",
        "    accuracy.append(k_accuracy)\n",
        "    precision.append(k_precision)\n",
        "    recall.append(k_recall)\n",
        "    f1_score.append(k_f1_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "80/80 [==============================] - 5s 18ms/step - loss: 0.2903 - accuracy: 0.9186\n",
            "Epoch 2/10\n",
            "80/80 [==============================] - 1s 15ms/step - loss: 0.1742 - accuracy: 0.9433\n",
            "Epoch 3/10\n",
            "80/80 [==============================] - 1s 15ms/step - loss: 0.1444 - accuracy: 0.9522\n",
            "Epoch 4/10\n",
            "80/80 [==============================] - 1s 16ms/step - loss: 0.1325 - accuracy: 0.9529\n",
            "Epoch 5/10\n",
            "80/80 [==============================] - 1s 16ms/step - loss: 0.1080 - accuracy: 0.9592\n",
            "Epoch 6/10\n",
            "80/80 [==============================] - 1s 16ms/step - loss: 0.0979 - accuracy: 0.9629\n",
            "Epoch 7/10\n",
            "80/80 [==============================] - 1s 16ms/step - loss: 0.0874 - accuracy: 0.9683\n",
            "Epoch 8/10\n",
            "80/80 [==============================] - 1s 16ms/step - loss: 0.0764 - accuracy: 0.9716\n",
            "Epoch 9/10\n",
            "80/80 [==============================] - 1s 16ms/step - loss: 0.0619 - accuracy: 0.9754\n",
            "Epoch 10/10\n",
            "80/80 [==============================] - 1s 16ms/step - loss: 0.0498 - accuracy: 0.9809\n",
            "80/80 [==============================] - 1s 4ms/step - loss: 0.1888 - accuracy: 0.9499\n",
            "Epoch 1/10\n",
            "80/80 [==============================] - 4s 18ms/step - loss: 0.2855 - accuracy: 0.9240\n",
            "Epoch 2/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.1765 - accuracy: 0.9459\n",
            "Epoch 3/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.1351 - accuracy: 0.9528\n",
            "Epoch 4/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.1258 - accuracy: 0.9565\n",
            "Epoch 5/10\n",
            "80/80 [==============================] - 1s 18ms/step - loss: 0.1116 - accuracy: 0.9614\n",
            "Epoch 6/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.0982 - accuracy: 0.9661\n",
            "Epoch 7/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.0904 - accuracy: 0.9677\n",
            "Epoch 8/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.0731 - accuracy: 0.9759\n",
            "Epoch 9/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.0553 - accuracy: 0.9791\n",
            "Epoch 10/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.0472 - accuracy: 0.9807\n",
            "80/80 [==============================] - 1s 4ms/step - loss: 0.1924 - accuracy: 0.9472\n",
            "Epoch 1/10\n",
            "80/80 [==============================] - 4s 17ms/step - loss: 0.2826 - accuracy: 0.9217\n",
            "Epoch 2/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.1755 - accuracy: 0.9434\n",
            "Epoch 3/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.1481 - accuracy: 0.9489\n",
            "Epoch 4/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.1153 - accuracy: 0.9594\n",
            "Epoch 5/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.1021 - accuracy: 0.9620\n",
            "Epoch 6/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.0981 - accuracy: 0.9630\n",
            "Epoch 7/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.0717 - accuracy: 0.9749\n",
            "Epoch 8/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.0688 - accuracy: 0.9721\n",
            "Epoch 9/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.0613 - accuracy: 0.9779\n",
            "Epoch 10/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.0485 - accuracy: 0.9828\n",
            "80/80 [==============================] - 1s 4ms/step - loss: 0.2032 - accuracy: 0.9413\n",
            "Epoch 1/10\n",
            "80/80 [==============================] - 4s 19ms/step - loss: 0.3102 - accuracy: 0.8891\n",
            "Epoch 2/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.1840 - accuracy: 0.9412\n",
            "Epoch 3/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.1454 - accuracy: 0.9489\n",
            "Epoch 4/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.1220 - accuracy: 0.9565\n",
            "Epoch 5/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.1052 - accuracy: 0.9616\n",
            "Epoch 6/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.0983 - accuracy: 0.9662\n",
            "Epoch 7/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.0849 - accuracy: 0.9695\n",
            "Epoch 8/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.0740 - accuracy: 0.9736\n",
            "Epoch 9/10\n",
            "80/80 [==============================] - 1s 18ms/step - loss: 0.0675 - accuracy: 0.9750\n",
            "Epoch 10/10\n",
            "80/80 [==============================] - 1s 18ms/step - loss: 0.0505 - accuracy: 0.9821\n",
            "80/80 [==============================] - 1s 5ms/step - loss: 0.1798 - accuracy: 0.9479\n",
            "Epoch 1/10\n",
            "80/80 [==============================] - 4s 17ms/step - loss: 0.2923 - accuracy: 0.9184\n",
            "Epoch 2/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.1699 - accuracy: 0.9433\n",
            "Epoch 3/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.1510 - accuracy: 0.9490\n",
            "Epoch 4/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.1286 - accuracy: 0.9549\n",
            "Epoch 5/10\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.1122 - accuracy: 0.9597\n",
            "Epoch 6/10\n",
            "80/80 [==============================] - 1s 16ms/step - loss: 0.0893 - accuracy: 0.9669\n",
            "Epoch 7/10\n",
            "80/80 [==============================] - 1s 16ms/step - loss: 0.0937 - accuracy: 0.9636\n",
            "Epoch 8/10\n",
            "80/80 [==============================] - 1s 18ms/step - loss: 0.0760 - accuracy: 0.9677\n",
            "Epoch 9/10\n",
            "80/80 [==============================] - 1s 16ms/step - loss: 0.0603 - accuracy: 0.9762\n",
            "Epoch 10/10\n",
            "80/80 [==============================] - 1s 16ms/step - loss: 0.0564 - accuracy: 0.9792\n",
            "80/80 [==============================] - 1s 4ms/step - loss: 0.1564 - accuracy: 0.9518\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loZoo9rBC7o_"
      },
      "source": [
        "def average(list):\n",
        "    return (sum(list) / len(list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TwH_N2-hiqM"
      },
      "source": [
        "accuracy = list(map(float, accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe5UbYFZhkQT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff3cc559-e420-4fab-a417-e51c152bcd0b"
      },
      "source": [
        "print(average(accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9476199999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0Eex-rnhlvN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65372d38-e8a2-4c94-fdda-b41bbfddea23"
      },
      "source": [
        "print(average(precision))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.58142411 0.96787623]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in_N8ny_hnu7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75686288-583a-4a6e-e7b6-58364996e29c"
      },
      "source": [
        "print(average(recall))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.49896776 0.97665624]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a6gh1q9hpKE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a079b655-52e4-4700-e280-8caab5f10351"
      },
      "source": [
        "print(average(f1_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.53559234 0.97223856]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}